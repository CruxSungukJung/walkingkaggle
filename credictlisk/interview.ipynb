{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위 Kagglers 프로파일 링 : Bestfitting, 현재 세계에서 # 1\n",
    "\n",
    "- 좋은 CV는 성공의 절반, 모델을 평가할 좋은 방법을 찾지 못하면 다음 단계로 넘어 가지 않을 것\n",
    "- 안정적인 CV를 구축하려면 데이터와 직면 한 문제에 대해 잘 알고 있어야 함 \n",
    "- 또한 검증 세트가 교육 세트 및 테스트 세트와 비슷한 분포를 가지고 있는지 확인하고 모델을 현지 CV 및 일반 LB 모두에서 향상 시키도록 노력할 것\n",
    "- 일부 시계열 대회에서는 일정 기간 동안 데이터를 유효성 검증 세트로 분류\n",
    "- 종종 보수적인 방식으로 최종 제출물을 선택. 안전한 모델의 가중 평균 앙상블을 선택하고 상대적으로 위험한 것을 선택. \n",
    "\n",
    "\n",
    "#  Mercedes-Benz Greener Masking Challing 마스킹 챌린지 - 1 위 수상자 인터뷰\n",
    "\n",
    "- 바이너리 변수의 양방향 상호 작용만으로도 많은 시간과 노력을 들인 67528 개의 새로운 변수를 탐색 할 수 있었음, 몇 가지 흥미로운 상호 작용을 신속하게 식별해야했습니다. \n",
    "- 변수의 중요성 보고서에서 개별 변수의 일부 쌍이 항상 \"가까운\" 것으로 나타났습니다. 단지 세 쌍의 개별 기능으로 양방향 상호 작용이 포함되었으며 추가적으로 3 방향 상호 작용이 포함되었습니다.\n",
    "- 30 배 교차 유효성 검사 수행 \n",
    "- 기능 선택. 변수 중요도 보고서 ( 모델 A의 경우 229 개 , 모델 B 의 경우 208 개) 에서처럼 XGBoost 에서 사용하는 변수를 유지하십시오 \n",
    "- 기능 선택. 백분율로 0.1 % 가 사용된 절단 값이었고 모델 A에서는 53, 모델 B에서는 47이었다\n",
    "\n",
    "\n",
    "# Instacart 시장 바구니 분석, 수상자 인터뷰 : 2 위, 오노 데라 카즈키\n",
    "\n",
    "- 식료품 재주문 을 예측하는 것\n",
    "- 재주문 예측 모델은 XGBoost를 사용하여 6 개의 다른 그래디언트 부스트 트리 모델을 만듭니다 (각 GBDT는 다른 임의 시드를 사용합니다). 그들의 예상을 평균하여 사용자 A가 다음 순서로 항목 B를 환매 할 확률을 얻습니다.\n",
    "- 없음 예측 모델은 XGBoost를 사용하여 17 가지 모델을 생성합니다. 이들 중 11 개는 0.01로 설정된 η 파라미터 (스텝 크기 축소)를 사용하고, 나머지는 0.002로 설정된 η 파라미터를 사용한다. 예측의 가중 평균을 취하여 사용자 A가 다음 순서로 항목을 환매하지 않을 확률을 구합니다.\n",
    "- 이 확률을 사용자 A가 다음 순서로 다시 구입할 항목의 이진 예 / 아니요 점수로 변환하기 위해 필자는 내가 작성한 특수한 F1 점수 최대화 알고리즘에 피드를 제공합니다.\n",
    "\n",
    "\n",
    "# Intel & MobileODT 자궁경 암 스크리닝 공모전, 1 위 수상자 인터뷰\n",
    "\n",
    "- 모든 사진을 100 개의 클러스터로 묶고 20 개의 무작위 클러스터를 검증 세트로 사용했습니다. 이는 모델에서 사용한 데이터 증가가 유용했는지 여부를 추적하는 데 도움이되었습니다.\n",
    "- 품질이 다른 두 개의 데이터 세트가있는 경우 추가 데이터 세트를 언더 샘플링하는 방법도 실험했습니다. 원본 : 추가 데이터 세트 이미지 개수 비율을 1 : 2로 유지하는 것이 최적이라는 것을 알았습니다 \n",
    "\n",
    "\n",
    "# March Machine Learning Mania, 1 위 수상자 인터뷰 : Andrew Landgraf\n",
    "\n",
    "- http://blog.kaggle.com/2017/05/19/march-machine-learning-mania-1st-place-winners-interview-andrew-landgraf/\n",
    "- 브래킷과 대회의 제출물을 10,000 번 시뮬레이션하여 최적의 제출물을 제시\n",
    "- 사후 확률 시뮬레이션에서 나는 rstanarm을 사용했다. 경쟁 제출물의 경우 lme4 매개 변수를 사용하여 시뮬레이션을 코딩했습니다.\n",
    "\n",
    "\n",
    "# March Machine Learning Mania 2017, 2 위 수상자 인터뷰 : Scott Kellert\n",
    "\n",
    "- http://blog.kaggle.com/2017/04/28/march-machine-learning-mania-2017-2nd-place-winners-interview-scott-kellert/\n",
    "-  과거에는 많은 알고리즘과 앙상블 기법을 시도했지만 Logistic Regression은 항상 승리했습니다\n",
    "- 올해는 선형 회귀 분석의 예측 간격 개념을 사용하여 확률을 산출 할 수있었습니다. 나는 단순히 포인트 스프레드 예측의 표준 오차 (일반적으로 약 10.55)를 계산하고 확률을 산출하기 위해 정상적인 CDF를 사용했다. 이 방법은 분류 기준보다 훨씬 뛰어납니다.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
