{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsung\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import lightgbm as lgbm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 깨달음\n",
    " - 무식하게 하지말자\n",
    " - 많다고 좋은거 아니다\n",
    " - 알고리즘은 맞는거 써야한다\n",
    "\n",
    "## 반성\n",
    " - 변수 조절 거의 안했다. 잘 좀 하자\n",
    " - 전처리에서 틀리면 다 틀린거다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --Test2--</br>\n",
    " 1. Test three parameters </br>\n",
    " 2. After check submission, record the LB score </br>\n",
    " 3. Stacking regard of the ratio </br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set2.csv')\n",
    "test = pd.read_csv('test_set2.csv')\n",
    "idSeries = np.array(test['id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625134\n",
      "(1450352, 26) (625134, 24)\n"
     ]
    }
   ],
   "source": [
    "print(len(idSeries))\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropoff_datetime', 'trip_duration'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450352, 261) (625134, 262)\n"
     ]
    }
   ],
   "source": [
    "train.drop(['id','pickup_datetime', 'dropoff_datetime'], axis = 1, inplace = True)\n",
    "test.drop(['id','pickup_datetime'], axis = 1, inplace = True)\n",
    "train, test = dummyBuilding(train.copy(), test.copy())\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ref = dict()\n",
    "for itr, x in enumerate(train['condition'].unique()):\n",
    "    ref[x] = itr\n",
    "train.drop(['id','pickup_datetime', 'dropoff_datetime'], axis = 1, inplace = True)\n",
    "test.drop(['id','pickup_datetime'], axis = 1, inplace = True)\n",
    "ix = 0\n",
    "for df in [train, test]:\n",
    "    df['condition']  = df['condition'].map(ref)\n",
    "if train.condition.nunique() == test.condition.nunique(): print('Go!')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr_th submission\n",
      "itr_th submission\n",
      "itr_th submission\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree = [0.6, 0.7, 0.8]\n",
    "for itr, bytree in enumerate(colsample_bytree):\n",
    "    subtitle = 'submission_ver_' + str(itr) + '.csv'\n",
    "    paramSet = {\n",
    "    'boosting_type': 'gbdt', 'objective': 'regression', 'nthread': -1,\n",
    "    'num_leaves': 32, 'learning_rate': 0.03, 'max_depth': -1,\n",
    "    'max_bin': 255, 'subsample_for_bin': 50000, 'metric': 'l2_root',\n",
    "    'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': bytree, 'reg_alpha': 1, 'reg_lambda': 1.2,\n",
    "    'min_split_gain': 0.6, 'min_child_weight': 4, 'min_child_samples': 10, 'scale_pos_weight': 1}\n",
    "    \n",
    "    prediction = lgbmTest(train, test, paramSet)\n",
    "    #prediction = np.exp(prediction) - 1\n",
    "    tmpSub = pd.DataFrame({'id':idSeries, 'trip_duration':prediction})\n",
    "    if tmpSub.shape[0] == len(idSeries):\n",
    "        print('itr_th submission')\n",
    "        tmpSub.to_csv(subtitle, index = False)\n",
    "        \n",
    "    else:\n",
    "        print('Different Length')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "동일 비율로 Stacking 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for itr in range(3):\n",
    "    subtitle = 'submission_ver_' + str(itr) + '.csv'\n",
    "    sub = pd.read_csv(subtitle)\n",
    "    res.append(np.array(sub['trip_duration'].values))\n",
    "    if itr == 0: idSeries = sub['id'].values\n",
    "    del sub\n",
    "res = np.array(res)\n",
    "meanPrediction = res.mean(axis=1)\n",
    "tmpSub = pd.DataFrame({'id':idSeries, 'trip_duration':prediction})\n",
    "tmpSub.to_csv('submission_StackMean.csv', index=  False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종결과 0.8984, 거의 꼴등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgbmTest(train, test, lgbm_params):\n",
    "    #train['trip_duration'] = np.log1p(train['trip_duration'])\n",
    "    Y_train = train['trip_duration'].copy()\n",
    "    train = train.drop(['trip_duration'], axis =1)\n",
    "    cv_sum = 0\n",
    "    fpred = []\n",
    "    lgbm_rounds = []\n",
    "    NFOLDS = 5\n",
    "    cv_score_list = []\n",
    "    \n",
    "    \"\"\"\n",
    "    kf = KFold(train.shape[0], n_folds = NFOLDS)\n",
    "    for ix, (train_index, cross_index) in enumerate(kf):\n",
    "        print(\"{} Fold \\n\".format(ix))\n",
    "        x_train, x_cross = train.iloc[train_index], train.iloc[cross_index]\n",
    "        y_train, y_cross = Y_train.iloc[train_index], Y_train.iloc[cross_index]\n",
    "    \n",
    "        dtrain = lgbm.Dataset(x_train, label = y_train.values, silent = True)\n",
    "        dvalid = lgbm.Dataset(x_cross, label = y_cross.values, silent = True)\n",
    "        model = lgbm.train(lgbm_params, train_set = dtrain, num_boost_round = 100000, valid_sets = dvalid,\n",
    "                      early_stopping_rounds = 100, verbose_eval = None,)\n",
    "        lgbm_rounds.append(model.best_iteration)\n",
    "        scores_val = model.predict(x_cross, num_iteration = model.best_iteration)\n",
    "        cv_score = sqrt(mean_squared_error(y_cross, scores_val))\n",
    "        print('eval-MAE : %.6f' % cv_score)\n",
    "        cv_score_list.append(cv_score)\n",
    "        cv_sum = cv_sum + cv_score\n",
    "    \n",
    "    score = cv_sum / NFOLDS\n",
    "    print(\"Average LogLikelihood: \", score)\n",
    "    for cv_index, cv_s in enumerate(cv_score_list):\n",
    "        print(cv_index+1, cv_s)\n",
    "    \n",
    "    print('test prediction')\n",
    "    bstRound = max(lgbm_rounds)\n",
    "    print('bst Round :', bstRound)\n",
    "    \"\"\"\n",
    "    dtrain_all = lgbm.Dataset(train, label = Y_train.values, silent = True)\n",
    "    model = lgbm.train(lgbm_params, dtrain_all)\n",
    "    predictions = model.predict(test, num_iteration = 200)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummyBuilding(train, test):\n",
    "    ix = 0\n",
    "    for df in [train, test]:\n",
    "        df_pickup_cluster = pd.get_dummies(df['pickup_cluster'], prefix = 'p', prefix_sep = '_')\n",
    "        df_dropoff_cluster = pd.get_dummies(df['dropoff_cluster'], prefix = 'd', prefix_sep = '_')\n",
    "        df_wday = pd.get_dummies(df['wday'], prefix = 'd', prefix_sep ='_')\n",
    "        df_hour = pd.get_dummies(df['hour'], prefix = 'h', prefix_sep = '_')\n",
    "        df_condition = pd.get_dummies(df['condition'], prefix = 'c', prefix_sep = '_')\n",
    "        \n",
    "        \n",
    "        df.drop(['passenger_count'], axis = 1, inplace = True)\n",
    "        df.drop(['wday', 'hour', 'condition'], axis = 1, inplace = True)\n",
    "        if ix == 0: df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'], axis =1, inplace = True)\n",
    "        else: df.drop(['pickup_longitude','pickup_latitude'], axis =1, inplace = True)\n",
    "        \n",
    "        df_Master = pd.concat([df, df_pickup_cluster, df_dropoff_cluster, \n",
    "                              df_wday, df_hour, df_condition], axis = 1)\n",
    "        del df, df_pickup_cluster, df_dropoff_cluster, df_wday, df_hour, df_condition\n",
    "        \n",
    "        if ix == 0: train = df_Master\n",
    "        else: test = df_Master\n",
    "        ix += 1\n",
    "    \n",
    "    return train, test    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
