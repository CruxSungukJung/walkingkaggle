{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rental Listing (Word2vec 활용) 최종 발표 - by 이상열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 로딩\n",
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks')\n",
    "color = sns.color_palette()\n",
    "\n",
    "import thinkstats2, thinkplot # Do \"pip install thinkx\", if necessary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Ref : https://github.com/KaggleBreak/problems/blob/master/2015_06_bagofwords/bagofwords.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words    \n",
    "    # The input is a single string (a raw movie review), and  he output is a single string (a preprocessed movie review)    \n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text()     \n",
    "    #    \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)     \n",
    "    #    \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                                 \n",
    "    #   \n",
    "    # 4. In Python, searching a set is much faster than searching    \n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                      \n",
    "    #     \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]       \n",
    "    #    \n",
    "    # 6. Join the words back into one string separated by space,     \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input data\n",
    "train_df=pd.read_json('./data/train.json')\n",
    "test_df=pd.read_json('./data/test.json')\n",
    "\n",
    "#basic features\n",
    "train_df[\"price_t\"] =train_df[\"price\"]/train_df[\"bedrooms\"]\n",
    "test_df[\"price_t\"] = test_df[\"price\"]/test_df[\"bedrooms\"] \n",
    "train_df[\"room_sum\"] = train_df[\"bedrooms\"]+train_df[\"bathrooms\"] \n",
    "test_df[\"room_sum\"] = test_df[\"bedrooms\"]+test_df[\"bathrooms\"] \n",
    "\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "\n",
    "# 원래 있던 original값들과 새로만든 feature를 넣어 feature_to_use 리스트 만듬\n",
    "features_to_use=[\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\"price_t\",\"num_photos\", \"num_features\", \"num_description_words\",\"listing_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_reviews = train_df[\"description\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_train_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy These Following Apartment Features As You Rent Here? Modern Designed Bathroom w/ a Deep Spa Soaking Tub? Room to Room AC/Heat? Real Oak Hardwood Floors? Rain Forest Shower Head? SS steel Appliances w/ Chef Gas Cook Oven & LG Fridge? washer /dryer in the apt? Cable Internet Ready? Granite Counter Top Kitchen w/ lot of cabinet storage spaceIt's Just A Few blocks To L Train<br /><br />Don't miss out!<br /><br />We have several great apartments in the immediate area.<br /><br />For additional information 687-878-2229<p><a  website_redacted \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"description\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 49352\n",
      "\n",
      "Review 2000 of 49352\n",
      "\n",
      "Review 3000 of 49352\n",
      "\n",
      "Review 4000 of 49352\n",
      "\n",
      "Review 5000 of 49352\n",
      "\n",
      "Review 6000 of 49352\n",
      "\n",
      "Review 7000 of 49352\n",
      "\n",
      "Review 8000 of 49352\n",
      "\n",
      "Review 9000 of 49352\n",
      "\n",
      "Review 10000 of 49352\n",
      "\n",
      "Review 11000 of 49352\n",
      "\n",
      "Review 12000 of 49352\n",
      "\n",
      "Review 13000 of 49352\n",
      "\n",
      "Review 14000 of 49352\n",
      "\n",
      "Review 15000 of 49352\n",
      "\n",
      "Review 16000 of 49352\n",
      "\n",
      "Review 17000 of 49352\n",
      "\n",
      "Review 18000 of 49352\n",
      "\n",
      "Review 19000 of 49352\n",
      "\n",
      "Review 20000 of 49352\n",
      "\n",
      "Review 21000 of 49352\n",
      "\n",
      "Review 22000 of 49352\n",
      "\n",
      "Review 23000 of 49352\n",
      "\n",
      "Review 24000 of 49352\n",
      "\n",
      "Review 25000 of 49352\n",
      "\n",
      "Review 26000 of 49352\n",
      "\n",
      "Review 27000 of 49352\n",
      "\n",
      "Review 28000 of 49352\n",
      "\n",
      "Review 29000 of 49352\n",
      "\n",
      "Review 30000 of 49352\n",
      "\n",
      "Review 31000 of 49352\n",
      "\n",
      "Review 32000 of 49352\n",
      "\n",
      "Review 33000 of 49352\n",
      "\n",
      "Review 34000 of 49352\n",
      "\n",
      "Review 35000 of 49352\n",
      "\n",
      "Review 36000 of 49352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 37000 of 49352\n",
      "\n",
      "Review 38000 of 49352\n",
      "\n",
      "Review 39000 of 49352\n",
      "\n",
      "Review 40000 of 49352\n",
      "\n",
      "Review 41000 of 49352\n",
      "\n",
      "Review 42000 of 49352\n",
      "\n",
      "Review 43000 of 49352\n",
      "\n",
      "Review 44000 of 49352\n",
      "\n",
      "Review 45000 of 49352\n",
      "\n",
      "Review 46000 of 49352\n",
      "\n",
      "Review 47000 of 49352\n",
      "\n",
      "Review 48000 of 49352\n",
      "\n",
      "Review 49000 of 49352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range( 0, num_reviews ):\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % ( i+1, num_reviews ))\n",
    "    clean_train_reviews.append( review_to_words( train_df[\"description\"].iloc[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top top west village location beautiful pre war building laundry basement live super apartment features large bedroom closet separate living room kitchen features granite tops dishwasher microwave included marble bathroom hardwood flooring building well maintained conveniently located near c e l trains surrounded many local cafe restaurants available november st move view apartment please contact via email call number listed bond new york real estate broker supports equal housing opportunity'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False ):    \n",
    "    # Function to convert a document to a sequence of words,    \n",
    "    # optionally removing stop words.  Returns a list of words.    \n",
    "    #    \n",
    "    # 1. Remove HTML    \n",
    "    review_text = BeautifulSoup(review).get_text()    \n",
    "    #      \n",
    "    # 2. Remove non-letters    \n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)    \n",
    "    #    \n",
    "    # 3. Convert words to lower case and split them    \n",
    "    words = review_text.lower().split()    \n",
    "    #    \n",
    "    # 4. Optionally remove stop words (false by default)    \n",
    "    if remove_stopwords:        \n",
    "        stops = set(stopwords.words(\"english\"))        \n",
    "        words = [w for w in words if not w in stops]    \n",
    "        #    \n",
    "        # 5. Return a list of words    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):    \n",
    "    # Function to split a review into parsed sentences. Returns a     \n",
    "    # list of sentences, where each sentence is a list of words    \n",
    "    #    \n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences    \n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    #    \n",
    "    # 2. Loop over each sentence    \n",
    "    sentences = []    \n",
    "    for raw_sentence in raw_sentences:        \n",
    "        # If a sentence is empty, skip it        \n",
    "        if len(raw_sentence) > 0:            \n",
    "            # Otherwise, call review_to_wordlist to get a list of words            \n",
    "            sentences.append( review_to_wordlist( raw_sentence, remove_stopwords ))    \n",
    "            #    \n",
    "            # Return the list of sentences (each sentence is a list of words,    \n",
    "            # so this returns a list of lists    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "#http://dev-strender.github.io/text%20processing/2015/04/05/Text-Processing-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy These Following Apartment Features As You Rent Here?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(train_df[\"description\"].iloc[0].strip())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modern Designed Bathroom w/ a Deep Spa Soaking Tub?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(train_df[\"description\"].iloc[0].strip())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modern', 'designed', 'bathroom', 'w', 'a', 'deep', 'spa', 'soaking', 'tub']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_wordlist(tokenizer.tokenize(train_df[\"description\"].iloc[0].strip())[1],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []  # Initialize an empty list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    }
   ],
   "source": [
    "print(\"Parsing sentences from training set\")\n",
    "for review in train_df[\"description\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for review in test_df[\"description\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583404\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'brand', 'new', 'bedroom', 'bath', 'apartmentenjoy', 'these', 'following', 'apartment', 'features', 'as', 'you', 'rent', 'here']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['modern', 'designed', 'bathroom', 'w', 'a', 'deep', 'spa', 'soaking', 'tub']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model (this will take some time)from gensim.models import word2vec\n",
    "print (\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "# If you don't plan to train the model any further, calling # init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "# It can be helpful to create a meaningful model name and # save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"data/300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'child'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rooms', 0.5115649700164795),\n",
       " ('area', 0.504125714302063),\n",
       " ('facility', 0.4711500406265259),\n",
       " ('quarters', 0.3973737359046936),\n",
       " ('den', 0.3888862431049347),\n",
       " ('facilities', 0.3870880603790283),\n",
       " ('roomcall', 0.3670872151851654),\n",
       " ('space', 0.36468058824539185),\n",
       " ('table', 0.3554668128490448),\n",
       " ('plus', 0.3495696783065796)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load(\"data/300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5507, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03375647,  0.01310883,  0.10571329, -0.07222398, -0.02576954,\n",
       "        0.02231651, -0.13409632,  0.05058629, -0.03423413,  0.00734794,\n",
       "        0.08761748,  0.06157919,  0.12037229,  0.02186078,  0.02035874,\n",
       "       -0.10238677, -0.07350989, -0.01296252, -0.01660722,  0.011027  ,\n",
       "       -0.00940361, -0.02979136,  0.08320071,  0.07187173,  0.08391818,\n",
       "       -0.0088168 ,  0.00340236, -0.01581809, -0.07416918, -0.0225496 ,\n",
       "       -0.01325632,  0.04519134,  0.02077758,  0.05758807, -0.03345492,\n",
       "       -0.05530149,  0.01606602,  0.01502326,  0.05069974,  0.04435149,\n",
       "       -0.01590603,  0.02161378,  0.06297158, -0.17924659,  0.00894811,\n",
       "        0.04633858, -0.08254109,  0.0657755 , -0.03758929,  0.04434289,\n",
       "       -0.0192487 ,  0.00477618,  0.1101819 , -0.04443537, -0.08881859,\n",
       "       -0.08462416, -0.09394614,  0.07577276, -0.05096463, -0.02676815,\n",
       "        0.02600441, -0.02582833,  0.01318391,  0.08707616, -0.0316474 ,\n",
       "       -0.01451613,  0.02299187,  0.04715926,  0.05699749, -0.04711325,\n",
       "       -0.02184927, -0.12204214,  0.0971426 , -0.1284786 ,  0.0340399 ,\n",
       "        0.04806297, -0.04668232,  0.06894641,  0.01736947, -0.0139148 ,\n",
       "        0.05316405, -0.0021081 ,  0.03991642, -0.04089459,  0.01061357,\n",
       "       -0.02615608,  0.08055244, -0.00174189,  0.01958761,  0.0738763 ,\n",
       "        0.06040885, -0.06409102,  0.05571393, -0.03384716,  0.03426234,\n",
       "       -0.07750247,  0.11977108, -0.04195597,  0.02025918, -0.0973298 ,\n",
       "        0.05233755, -0.01743465,  0.03268665,  0.03626919, -0.07745991,\n",
       "        0.03525935, -0.01331544,  0.07132999, -0.06006908, -0.04213475,\n",
       "       -0.02605472,  0.11473838, -0.04554685, -0.00399394,  0.0282106 ,\n",
       "        0.14142786, -0.0161302 , -0.01029643, -0.04849787,  0.04890111,\n",
       "       -0.02969851, -0.01370218,  0.04702023, -0.01206294,  0.02622497,\n",
       "        0.03878778,  0.04528393, -0.05287208, -0.0617082 , -0.02699671,\n",
       "       -0.06466132,  0.01503905,  0.10293702,  0.01900573,  0.01701853,\n",
       "       -0.00887238, -0.05431644,  0.05381907, -0.03652974, -0.09640616,\n",
       "        0.02835371,  0.06516561,  0.10459914, -0.01606465, -0.06436084,\n",
       "       -0.02878235, -0.0614326 ,  0.011194  ,  0.00679427,  0.04062873,\n",
       "       -0.0287141 , -0.09546786, -0.05181285, -0.06119843,  0.02302454,\n",
       "        0.0810544 , -0.06951232,  0.07484717,  0.11138543,  0.06024707,\n",
       "        0.0626232 ,  0.01224652,  0.02475584, -0.05148146,  0.01123709,\n",
       "       -0.11492112, -0.00935102, -0.01361426,  0.00726874, -0.0135353 ,\n",
       "        0.06249117,  0.11536564,  0.01000076, -0.07467951,  0.0152876 ,\n",
       "       -0.10312342,  0.02663107,  0.04675335,  0.06311378,  0.04019703,\n",
       "       -0.01166711,  0.03250339, -0.03893801,  0.02264306,  0.10043052,\n",
       "        0.02235198, -0.02385478, -0.09146765,  0.03287463, -0.03053276,\n",
       "       -0.10269395,  0.01434856, -0.07992121, -0.06021889,  0.0251995 ,\n",
       "       -0.02495232, -0.10707124, -0.09352249, -0.06294643, -0.14251946,\n",
       "        0.01154541, -0.04342143,  0.01399636,  0.04177612, -0.09013361,\n",
       "       -0.0531817 , -0.03882939, -0.02007166, -0.01908991,  0.05068068,\n",
       "       -0.03526183, -0.01347076, -0.00388813, -0.07955489, -0.08364137,\n",
       "        0.0371628 , -0.02227536,  0.01348878,  0.05866827, -0.01651946,\n",
       "       -0.03728125,  0.01696625, -0.00630566, -0.11913161,  0.13995102,\n",
       "        0.01201408,  0.05273514, -0.03619578,  0.10741062,  0.00944858,\n",
       "        0.00903644,  0.06633519,  0.04365248,  0.10877363, -0.06789923,\n",
       "        0.02190459,  0.02394062, -0.00457889,  0.05423344, -0.07783014,\n",
       "       -0.04613398,  0.04419537, -0.00292318,  0.02313018, -0.03045323,\n",
       "        0.00875616, -0.05324893,  0.03099575, -0.0074483 ,  0.03774474,\n",
       "        0.00359596,  0.03182169,  0.1461339 , -0.02093171,  0.04368783,\n",
       "        0.01073607, -0.09939223, -0.06793786, -0.05181919,  0.10045557,\n",
       "       -0.01727994, -0.01468893,  0.09073042, -0.00212695, -0.08965752,\n",
       "       -0.01725051,  0.07733835, -0.03706652, -0.04163487,  0.03340451,\n",
       "        0.02979822, -0.09409873, -0.02120364, -0.03241115,  0.00648872,\n",
       "        0.04581289,  0.02942365,  0.05224624, -0.00500303, -0.02321253,\n",
       "       -0.03689464,  0.08370622,  0.01165976,  0.02457424,  0.07377023,\n",
       "        0.02510428, -0.01619868,  0.04361138, -0.01232642,  0.08814032,\n",
       "       -0.05907618, -0.01968088,  0.04012523, -0.0221856 ,  0.03651719,\n",
       "       -0.12272698, -0.05546434, -0.08422288,  0.064141  , -0.01208547], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"building\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Words To Paragraphs, Attempt 1: Vector Averaging¶\n",
    "import numpy as np  \n",
    "# Make sure that numpy is imported\n",
    "def makeFeatureVec(words, model, num_features):    \n",
    "    # Function to average all of the word vectors in a given    \n",
    "    # paragraph    \n",
    "    #    \n",
    "    # Pre-initialize an empty numpy array (for speed)    \n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")    \n",
    "    #    \n",
    "    nwords = 0.    \n",
    "    #     \n",
    "    # Index2word is a list that contains the names of the words in     \n",
    "    # the model's vocabulary. Convert it to a set, for speed     \n",
    "    index2word_set = set(model.index2word)    \n",
    "    #    \n",
    "    # Loop over each word in the review and, if it is in the model's    \n",
    "    # vocaublary, add its feature vector to the total    \n",
    "    for word in words:        \n",
    "        if word in index2word_set:             \n",
    "            nwords = nwords + 1.            \n",
    "            featureVec = np.add(featureVec,model[word])    \n",
    "    #     \n",
    "    # Divide the result by the number of words to get the average    \n",
    "    featureVec = np.divide(featureVec,nwords)    \n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):    \n",
    "    # Given a set of reviews (each one a list of words), calculate     \n",
    "    # the average feature vector for each one and return a 2D numpy array     \n",
    "    #     \n",
    "    # Initialize a counter    \n",
    "    counter = 0.    \n",
    "    #     \n",
    "    # Preallocate a 2D numpy array, for speed    \n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")    \n",
    "    #     \n",
    "    # Loop through the reviews    \n",
    "    for review in reviews:       \n",
    "        #       \n",
    "        # Print a status message every 1000th review       \n",
    "        if counter%1000. == 0.:           \n",
    "            print (\"Review %d of %d\" % (counter, len(reviews)))      \n",
    "            #        \n",
    "            # Call the function (defined above) that makes average feature vectors       \n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)       \n",
    "        #       \n",
    "        # Increment the counter       \n",
    "        counter = counter + 1.    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_train_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 49352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 49352\n",
      "Review 2000 of 49352\n",
      "Review 3000 of 49352\n",
      "Review 4000 of 49352\n",
      "Review 5000 of 49352\n",
      "Review 6000 of 49352\n",
      "Review 7000 of 49352\n",
      "Review 8000 of 49352\n",
      "Review 9000 of 49352\n",
      "Review 10000 of 49352\n",
      "Review 11000 of 49352\n",
      "Review 12000 of 49352\n",
      "Review 13000 of 49352\n",
      "Review 14000 of 49352\n",
      "Review 15000 of 49352\n",
      "Review 16000 of 49352\n",
      "Review 17000 of 49352\n",
      "Review 18000 of 49352\n",
      "Review 19000 of 49352\n",
      "Review 20000 of 49352\n",
      "Review 21000 of 49352\n",
      "Review 22000 of 49352\n",
      "Review 23000 of 49352\n",
      "Review 24000 of 49352\n",
      "Review 25000 of 49352\n",
      "Review 26000 of 49352\n",
      "Review 27000 of 49352\n",
      "Review 28000 of 49352\n",
      "Review 29000 of 49352\n",
      "Review 30000 of 49352\n",
      "Review 31000 of 49352\n",
      "Review 32000 of 49352\n",
      "Review 33000 of 49352\n",
      "Review 34000 of 49352\n",
      "Review 35000 of 49352\n",
      "Review 36000 of 49352\n",
      "Review 37000 of 49352\n",
      "Review 38000 of 49352\n",
      "Review 39000 of 49352\n",
      "Review 40000 of 49352\n",
      "Review 41000 of 49352\n",
      "Review 42000 of 49352\n",
      "Review 43000 of 49352\n",
      "Review 44000 of 49352\n",
      "Review 45000 of 49352\n",
      "Review 46000 of 49352\n",
      "Review 47000 of 49352\n",
      "Review 48000 of 49352\n",
      "Review 49000 of 49352\n"
     ]
    }
   ],
   "source": [
    "for review in train_df[\"description\"]:    \n",
    "    clean_train_reviews.append( review_to_wordlist( review, remove_stopwords=True ))\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00055333, -0.0183891 ,  0.00794306, ...,  0.01932015,\n",
       "         0.02837954, -0.00214033],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.0116992 , -0.01275395,  0.0106168 , ..., -0.00145144,\n",
       "         0.00130717,  0.00064602],\n",
       "       ..., \n",
       "       [ 0.02533396, -0.02877892,  0.01583145, ...,  0.0025978 ,\n",
       "         0.00494621, -0.00066494],\n",
       "       [-0.02255059, -0.00497683,  0.01731538, ...,  0.01652828,\n",
       "         0.01012026, -0.00421657],\n",
       "       [ 0.00916268, -0.01646173,  0.00261846, ...,  0.00139349,\n",
       "         0.00044382,  0.00409133]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating average feature vecs for test reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 74659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 74659\n",
      "Review 2000 of 74659\n",
      "Review 3000 of 74659\n",
      "Review 4000 of 74659\n",
      "Review 5000 of 74659\n",
      "Review 6000 of 74659\n",
      "Review 7000 of 74659\n",
      "Review 8000 of 74659\n",
      "Review 9000 of 74659\n",
      "Review 10000 of 74659\n",
      "Review 11000 of 74659\n",
      "Review 12000 of 74659\n",
      "Review 13000 of 74659\n",
      "Review 14000 of 74659\n",
      "Review 15000 of 74659\n",
      "Review 16000 of 74659\n",
      "Review 17000 of 74659\n",
      "Review 18000 of 74659\n",
      "Review 19000 of 74659\n",
      "Review 20000 of 74659\n",
      "Review 21000 of 74659\n",
      "Review 22000 of 74659\n",
      "Review 23000 of 74659\n",
      "Review 24000 of 74659\n",
      "Review 25000 of 74659\n",
      "Review 26000 of 74659\n",
      "Review 27000 of 74659\n",
      "Review 28000 of 74659\n",
      "Review 29000 of 74659\n",
      "Review 30000 of 74659\n",
      "Review 31000 of 74659\n",
      "Review 32000 of 74659\n",
      "Review 33000 of 74659\n",
      "Review 34000 of 74659\n",
      "Review 35000 of 74659\n",
      "Review 36000 of 74659\n",
      "Review 37000 of 74659\n",
      "Review 38000 of 74659\n",
      "Review 39000 of 74659\n",
      "Review 40000 of 74659\n",
      "Review 41000 of 74659\n",
      "Review 42000 of 74659\n",
      "Review 43000 of 74659\n",
      "Review 44000 of 74659\n",
      "Review 45000 of 74659\n",
      "Review 46000 of 74659\n",
      "Review 47000 of 74659\n",
      "Review 48000 of 74659\n",
      "Review 49000 of 74659\n",
      "Review 50000 of 74659\n",
      "Review 51000 of 74659\n",
      "Review 52000 of 74659\n",
      "Review 53000 of 74659\n",
      "Review 54000 of 74659\n",
      "Review 55000 of 74659\n",
      "Review 56000 of 74659\n",
      "Review 57000 of 74659\n",
      "Review 58000 of 74659\n",
      "Review 59000 of 74659\n",
      "Review 60000 of 74659\n",
      "Review 61000 of 74659\n",
      "Review 62000 of 74659\n",
      "Review 63000 of 74659\n",
      "Review 64000 of 74659\n",
      "Review 65000 of 74659\n",
      "Review 66000 of 74659\n",
      "Review 67000 of 74659\n",
      "Review 68000 of 74659\n",
      "Review 69000 of 74659\n",
      "Review 70000 of 74659\n",
      "Review 71000 of 74659\n",
      "Review 72000 of 74659\n",
      "Review 73000 of 74659\n",
      "Review 74000 of 74659\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating average feature vecs for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test_df[\"description\"]:    \n",
    "    clean_test_reviews.append( review_to_wordlist( review, remove_stopwords=True ))\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0138732 , -0.02027832, -0.01282191, ...,  0.00305912,\n",
       "        -0.00083949,  0.00687549],\n",
       "       [ 0.01392211, -0.01963464,  0.00797748, ...,  0.01133472,\n",
       "         0.00225028,  0.0175917 ],\n",
       "       [-0.00418794, -0.00298554,  0.00774313, ...,  0.0045233 ,\n",
       "         0.01313456,  0.00084954],\n",
       "       ..., \n",
       "       [-0.01202475, -0.02804098, -0.00189287, ...,  0.00702829,\n",
       "         0.02023262, -0.00015413],\n",
       "       [ 0.00467204, -0.00276794,  0.01279011, ..., -0.00600866,\n",
       "        -0.00233   , -0.00191295],\n",
       "       [ 0.01138543, -0.02832986,  0.00448089, ...,  0.00433501,\n",
       "         0.01560072,  0.0004311 ]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 300)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 300)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataVecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://flonelin.wordpress.com/2016/07/26/tuning-xgboostextream-gradient-boosting/\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.03\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7 # 70프로만 뽑겠다\n",
    "    param['colsample_bytree'] = 0.7 # 컬럼의 ratio 최대 몇개만 쓰겠다라는 의미?\n",
    "    param['seed'] = seed_val # 초기값 설정 랜덤 안되게\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y) # D매트릭스로 바꿔줘야 한다.\n",
    "\n",
    "    # test의 타겟값을 넣은 xgb model\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    # test의 타겟값을 넣지 않은 xgb model\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train data 의 수만큼의 list를 만듬\n",
    "index=list(range(train_df.shape[0]))\n",
    "random.shuffle(index) # 값 셔플\n",
    "a=[np.nan]*len(train_df) # 데이터 수만큼 리스트 만들고\n",
    "b=[np.nan]*len(train_df)\n",
    "c=[np.nan]*len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 5등분할 계획\n",
    "# 매니저id를 key로 하는 building_level을 만듦\n",
    "for i in range(5): \n",
    "    building_level={}\n",
    "    for j in train_df['manager_id'].values:\n",
    "        building_level[j]=[0,0,0]\n",
    "    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
    "    train_index=list(set(index).difference(test_index))\n",
    "    for j in train_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if temp['interest_level']=='low':\n",
    "            building_level[temp['manager_id']][0]+=1\n",
    "        if temp['interest_level']=='medium':\n",
    "            building_level[temp['manager_id']][1]+=1\n",
    "        if temp['interest_level']=='high':\n",
    "            building_level[temp['manager_id']][2]+=1\n",
    "    for j in test_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if sum(building_level[temp['manager_id']])!=0:\n",
    "            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
    "            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
    "            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
    "train_df['manager_level_low']=a\n",
    "train_df['manager_level_medium']=b\n",
    "train_df['manager_level_high']=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이번엔 train데이터를 통해 집계한 매니저에 대한 'interest level별 count정보'로 test데이터의 'manager에 대한 interest level별 비율정보'을 구함\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "building_level={}\n",
    "for j in train_df['manager_id'].values:\n",
    "    building_level[j]=[0,0,0]\n",
    "for j in range(train_df.shape[0]):\n",
    "    temp=train_df.iloc[j]\n",
    "    if temp['interest_level']=='low':\n",
    "        building_level[temp['manager_id']][0]+=1\n",
    "    if temp['interest_level']=='medium':\n",
    "        building_level[temp['manager_id']][1]+=1\n",
    "    if temp['interest_level']=='high':\n",
    "        building_level[temp['manager_id']][2]+=1\n",
    "\n",
    "for i in test_df['manager_id'].values:\n",
    "    if i not in building_level.keys():\n",
    "        a.append(np.nan)\n",
    "        b.append(np.nan)\n",
    "        c.append(np.nan)\n",
    "    else:\n",
    "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
    "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
    "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
    "test_df['manager_level_low']=a\n",
    "test_df['manager_level_medium']=b\n",
    "test_df['manager_level_high']=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#위에서 애써만든 매니저 평가정보를 여기에서 feature에 포함시킴\n",
    "features_to_use.append('manager_level_low') \n",
    "features_to_use.append('manager_level_medium') \n",
    "features_to_use.append('manager_level_high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 범주형 데이터를 넣는 과정\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder() #범주형 변수를 사용하기 위해 팩터화시키는것\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                                                         \n",
      "10000     Doorman Elevator Fitness_Center Cats_Allowed D...\n",
      "100004    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
      "100007                               Hardwood_Floors No_Fee\n",
      "100013                                              Pre-War\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# original데이터의 features컬럼을 tfidf 팩터화\n",
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original데이터의 features컬럼을 tfidf 팩터화\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bathrooms',\n",
       " 'bedrooms',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'price',\n",
       " 'price_t',\n",
       " 'num_photos',\n",
       " 'num_features',\n",
       " 'num_description_words',\n",
       " 'listing_id',\n",
       " 'manager_level_low',\n",
       " 'manager_level_medium',\n",
       " 'manager_level_high',\n",
       " 'display_address',\n",
       " 'manager_id',\n",
       " 'building_id',\n",
       " 'street_address']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xgb에 넣기위해 자료구조를 만듬\n",
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse, trainDataVecs]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse, testDataVecs]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 517) (74659, 517)\n"
     ]
    }
   ],
   "source": [
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.07956\ttest-mlogloss:1.08009\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:1.06158\ttest-mlogloss:1.06264\n",
      "[2]\ttrain-mlogloss:1.04326\ttest-mlogloss:1.04477\n",
      "[3]\ttrain-mlogloss:1.02594\ttest-mlogloss:1.02795\n",
      "[4]\ttrain-mlogloss:1.00978\ttest-mlogloss:1.0123\n",
      "[5]\ttrain-mlogloss:0.993963\ttest-mlogloss:0.997064\n",
      "[6]\ttrain-mlogloss:0.978094\ttest-mlogloss:0.981778\n",
      "[7]\ttrain-mlogloss:0.963401\ttest-mlogloss:0.967504\n",
      "[8]\ttrain-mlogloss:0.949002\ttest-mlogloss:0.953572\n",
      "[9]\ttrain-mlogloss:0.935136\ttest-mlogloss:0.940238\n",
      "[10]\ttrain-mlogloss:0.922337\ttest-mlogloss:0.927935\n",
      "[11]\ttrain-mlogloss:0.910074\ttest-mlogloss:0.916082\n",
      "[12]\ttrain-mlogloss:0.898003\ttest-mlogloss:0.904555\n",
      "[13]\ttrain-mlogloss:0.886384\ttest-mlogloss:0.893302\n",
      "[14]\ttrain-mlogloss:0.875145\ttest-mlogloss:0.882631\n",
      "[15]\ttrain-mlogloss:0.864804\ttest-mlogloss:0.8728\n",
      "[16]\ttrain-mlogloss:0.85447\ttest-mlogloss:0.862851\n",
      "[17]\ttrain-mlogloss:0.844595\ttest-mlogloss:0.853483\n",
      "[18]\ttrain-mlogloss:0.835217\ttest-mlogloss:0.844545\n",
      "[19]\ttrain-mlogloss:0.826217\ttest-mlogloss:0.836037\n",
      "[20]\ttrain-mlogloss:0.817559\ttest-mlogloss:0.827823\n",
      "[21]\ttrain-mlogloss:0.809071\ttest-mlogloss:0.819816\n",
      "[22]\ttrain-mlogloss:0.800866\ttest-mlogloss:0.81205\n",
      "[23]\ttrain-mlogloss:0.792996\ttest-mlogloss:0.80462\n",
      "[24]\ttrain-mlogloss:0.785552\ttest-mlogloss:0.7976\n",
      "[25]\ttrain-mlogloss:0.778149\ttest-mlogloss:0.790694\n",
      "[26]\ttrain-mlogloss:0.771233\ttest-mlogloss:0.784265\n",
      "[27]\ttrain-mlogloss:0.764273\ttest-mlogloss:0.777769\n",
      "[28]\ttrain-mlogloss:0.757972\ttest-mlogloss:0.77185\n",
      "[29]\ttrain-mlogloss:0.751502\ttest-mlogloss:0.765784\n",
      "[30]\ttrain-mlogloss:0.745921\ttest-mlogloss:0.760531\n",
      "[31]\ttrain-mlogloss:0.739967\ttest-mlogloss:0.754969\n",
      "[32]\ttrain-mlogloss:0.734389\ttest-mlogloss:0.749801\n",
      "[33]\ttrain-mlogloss:0.728674\ttest-mlogloss:0.744556\n",
      "[34]\ttrain-mlogloss:0.723054\ttest-mlogloss:0.739397\n",
      "[35]\ttrain-mlogloss:0.717886\ttest-mlogloss:0.734568\n",
      "[36]\ttrain-mlogloss:0.712976\ttest-mlogloss:0.730001\n",
      "[37]\ttrain-mlogloss:0.708275\ttest-mlogloss:0.725674\n",
      "[38]\ttrain-mlogloss:0.703987\ttest-mlogloss:0.721669\n",
      "[39]\ttrain-mlogloss:0.699575\ttest-mlogloss:0.717727\n",
      "[40]\ttrain-mlogloss:0.695174\ttest-mlogloss:0.713755\n",
      "[41]\ttrain-mlogloss:0.690791\ttest-mlogloss:0.70975\n",
      "[42]\ttrain-mlogloss:0.686716\ttest-mlogloss:0.706141\n",
      "[43]\ttrain-mlogloss:0.682698\ttest-mlogloss:0.702515\n",
      "[44]\ttrain-mlogloss:0.678771\ttest-mlogloss:0.698979\n",
      "[45]\ttrain-mlogloss:0.674984\ttest-mlogloss:0.695569\n",
      "[46]\ttrain-mlogloss:0.67124\ttest-mlogloss:0.692217\n",
      "[47]\ttrain-mlogloss:0.667505\ttest-mlogloss:0.688813\n",
      "[48]\ttrain-mlogloss:0.66378\ttest-mlogloss:0.685515\n",
      "[49]\ttrain-mlogloss:0.660314\ttest-mlogloss:0.682438\n",
      "[50]\ttrain-mlogloss:0.657033\ttest-mlogloss:0.679485\n",
      "[51]\ttrain-mlogloss:0.653961\ttest-mlogloss:0.676771\n",
      "[52]\ttrain-mlogloss:0.650786\ttest-mlogloss:0.673998\n",
      "[53]\ttrain-mlogloss:0.647847\ttest-mlogloss:0.671407\n",
      "[54]\ttrain-mlogloss:0.645231\ttest-mlogloss:0.669028\n",
      "[55]\ttrain-mlogloss:0.642332\ttest-mlogloss:0.66653\n",
      "[56]\ttrain-mlogloss:0.639689\ttest-mlogloss:0.66427\n",
      "[57]\ttrain-mlogloss:0.637032\ttest-mlogloss:0.662083\n",
      "[58]\ttrain-mlogloss:0.634312\ttest-mlogloss:0.659718\n",
      "[59]\ttrain-mlogloss:0.631839\ttest-mlogloss:0.657634\n",
      "[60]\ttrain-mlogloss:0.629321\ttest-mlogloss:0.655404\n",
      "[61]\ttrain-mlogloss:0.626897\ttest-mlogloss:0.653292\n",
      "[62]\ttrain-mlogloss:0.624549\ttest-mlogloss:0.651301\n",
      "[63]\ttrain-mlogloss:0.622253\ttest-mlogloss:0.649342\n",
      "[64]\ttrain-mlogloss:0.619867\ttest-mlogloss:0.647289\n",
      "[65]\ttrain-mlogloss:0.617735\ttest-mlogloss:0.645548\n",
      "[66]\ttrain-mlogloss:0.615443\ttest-mlogloss:0.64358\n",
      "[67]\ttrain-mlogloss:0.613279\ttest-mlogloss:0.641784\n",
      "[68]\ttrain-mlogloss:0.611121\ttest-mlogloss:0.640108\n",
      "[69]\ttrain-mlogloss:0.609058\ttest-mlogloss:0.638409\n",
      "[70]\ttrain-mlogloss:0.60741\ttest-mlogloss:0.637012\n",
      "[71]\ttrain-mlogloss:0.605612\ttest-mlogloss:0.635503\n",
      "[72]\ttrain-mlogloss:0.60376\ttest-mlogloss:0.633963\n",
      "[73]\ttrain-mlogloss:0.601813\ttest-mlogloss:0.632419\n",
      "[74]\ttrain-mlogloss:0.60011\ttest-mlogloss:0.631011\n",
      "[75]\ttrain-mlogloss:0.598415\ttest-mlogloss:0.629621\n",
      "[76]\ttrain-mlogloss:0.596725\ttest-mlogloss:0.6283\n",
      "[77]\ttrain-mlogloss:0.594988\ttest-mlogloss:0.626947\n",
      "[78]\ttrain-mlogloss:0.593301\ttest-mlogloss:0.625718\n",
      "[79]\ttrain-mlogloss:0.591742\ttest-mlogloss:0.624471\n",
      "[80]\ttrain-mlogloss:0.590059\ttest-mlogloss:0.623195\n",
      "[81]\ttrain-mlogloss:0.588409\ttest-mlogloss:0.621884\n",
      "[82]\ttrain-mlogloss:0.586826\ttest-mlogloss:0.620724\n",
      "[83]\ttrain-mlogloss:0.585275\ttest-mlogloss:0.619467\n",
      "[84]\ttrain-mlogloss:0.583941\ttest-mlogloss:0.618529\n",
      "[85]\ttrain-mlogloss:0.582465\ttest-mlogloss:0.617356\n",
      "[86]\ttrain-mlogloss:0.581038\ttest-mlogloss:0.616278\n",
      "[87]\ttrain-mlogloss:0.579711\ttest-mlogloss:0.615268\n",
      "[88]\ttrain-mlogloss:0.578467\ttest-mlogloss:0.61436\n",
      "[89]\ttrain-mlogloss:0.577206\ttest-mlogloss:0.613309\n",
      "[90]\ttrain-mlogloss:0.576062\ttest-mlogloss:0.612431\n",
      "[91]\ttrain-mlogloss:0.574805\ttest-mlogloss:0.611518\n",
      "[92]\ttrain-mlogloss:0.573428\ttest-mlogloss:0.610453\n",
      "[93]\ttrain-mlogloss:0.572262\ttest-mlogloss:0.609625\n",
      "[94]\ttrain-mlogloss:0.571071\ttest-mlogloss:0.608745\n",
      "[95]\ttrain-mlogloss:0.570035\ttest-mlogloss:0.607998\n",
      "[96]\ttrain-mlogloss:0.568874\ttest-mlogloss:0.607149\n",
      "[97]\ttrain-mlogloss:0.567701\ttest-mlogloss:0.606356\n",
      "[98]\ttrain-mlogloss:0.566599\ttest-mlogloss:0.605551\n",
      "[99]\ttrain-mlogloss:0.56554\ttest-mlogloss:0.604793\n",
      "[100]\ttrain-mlogloss:0.564435\ttest-mlogloss:0.603976\n",
      "[101]\ttrain-mlogloss:0.563173\ttest-mlogloss:0.603041\n",
      "[102]\ttrain-mlogloss:0.562079\ttest-mlogloss:0.602268\n",
      "[103]\ttrain-mlogloss:0.561165\ttest-mlogloss:0.601685\n",
      "[104]\ttrain-mlogloss:0.56013\ttest-mlogloss:0.600953\n",
      "[105]\ttrain-mlogloss:0.559175\ttest-mlogloss:0.600261\n",
      "[106]\ttrain-mlogloss:0.558283\ttest-mlogloss:0.599663\n",
      "[107]\ttrain-mlogloss:0.557209\ttest-mlogloss:0.598944\n",
      "[108]\ttrain-mlogloss:0.556301\ttest-mlogloss:0.598348\n",
      "[109]\ttrain-mlogloss:0.555316\ttest-mlogloss:0.597713\n",
      "[110]\ttrain-mlogloss:0.554481\ttest-mlogloss:0.597116\n",
      "[111]\ttrain-mlogloss:0.553617\ttest-mlogloss:0.596603\n",
      "[112]\ttrain-mlogloss:0.552664\ttest-mlogloss:0.595942\n",
      "[113]\ttrain-mlogloss:0.551726\ttest-mlogloss:0.595376\n",
      "[114]\ttrain-mlogloss:0.550829\ttest-mlogloss:0.594835\n",
      "[115]\ttrain-mlogloss:0.550197\ttest-mlogloss:0.594391\n",
      "[116]\ttrain-mlogloss:0.549226\ttest-mlogloss:0.59369\n",
      "[117]\ttrain-mlogloss:0.548279\ttest-mlogloss:0.593017\n",
      "[118]\ttrain-mlogloss:0.547619\ttest-mlogloss:0.592625\n",
      "[119]\ttrain-mlogloss:0.54682\ttest-mlogloss:0.592124\n",
      "[120]\ttrain-mlogloss:0.545974\ttest-mlogloss:0.591585\n",
      "[121]\ttrain-mlogloss:0.54509\ttest-mlogloss:0.591072\n",
      "[122]\ttrain-mlogloss:0.544155\ttest-mlogloss:0.590513\n",
      "[123]\ttrain-mlogloss:0.543426\ttest-mlogloss:0.590019\n",
      "[124]\ttrain-mlogloss:0.542785\ttest-mlogloss:0.589642\n",
      "[125]\ttrain-mlogloss:0.54199\ttest-mlogloss:0.589145\n",
      "[126]\ttrain-mlogloss:0.541218\ttest-mlogloss:0.588737\n",
      "[127]\ttrain-mlogloss:0.540409\ttest-mlogloss:0.588257\n",
      "[128]\ttrain-mlogloss:0.539711\ttest-mlogloss:0.587812\n",
      "[129]\ttrain-mlogloss:0.53891\ttest-mlogloss:0.587453\n",
      "[130]\ttrain-mlogloss:0.538388\ttest-mlogloss:0.58709\n",
      "[131]\ttrain-mlogloss:0.537438\ttest-mlogloss:0.586493\n",
      "[132]\ttrain-mlogloss:0.536597\ttest-mlogloss:0.585971\n",
      "[133]\ttrain-mlogloss:0.535802\ttest-mlogloss:0.585539\n",
      "[134]\ttrain-mlogloss:0.535081\ttest-mlogloss:0.585108\n",
      "[135]\ttrain-mlogloss:0.534442\ttest-mlogloss:0.584744\n",
      "[136]\ttrain-mlogloss:0.533686\ttest-mlogloss:0.584295\n",
      "[137]\ttrain-mlogloss:0.532946\ttest-mlogloss:0.583862\n",
      "[138]\ttrain-mlogloss:0.532344\ttest-mlogloss:0.583522\n",
      "[139]\ttrain-mlogloss:0.531722\ttest-mlogloss:0.583176\n",
      "[140]\ttrain-mlogloss:0.531257\ttest-mlogloss:0.582872\n",
      "[141]\ttrain-mlogloss:0.530517\ttest-mlogloss:0.58262\n",
      "[142]\ttrain-mlogloss:0.52984\ttest-mlogloss:0.582194\n",
      "[143]\ttrain-mlogloss:0.529151\ttest-mlogloss:0.581875\n",
      "[144]\ttrain-mlogloss:0.528471\ttest-mlogloss:0.581556\n",
      "[145]\ttrain-mlogloss:0.527891\ttest-mlogloss:0.581154\n",
      "[146]\ttrain-mlogloss:0.527275\ttest-mlogloss:0.580843\n",
      "[147]\ttrain-mlogloss:0.526614\ttest-mlogloss:0.580475\n",
      "[148]\ttrain-mlogloss:0.525964\ttest-mlogloss:0.580187\n",
      "[149]\ttrain-mlogloss:0.525455\ttest-mlogloss:0.579915\n",
      "[150]\ttrain-mlogloss:0.524719\ttest-mlogloss:0.579502\n",
      "[151]\ttrain-mlogloss:0.5242\ttest-mlogloss:0.579234\n",
      "[152]\ttrain-mlogloss:0.52353\ttest-mlogloss:0.578893\n",
      "[153]\ttrain-mlogloss:0.522985\ttest-mlogloss:0.57865\n",
      "[154]\ttrain-mlogloss:0.522298\ttest-mlogloss:0.578251\n",
      "[155]\ttrain-mlogloss:0.52172\ttest-mlogloss:0.577947\n",
      "[156]\ttrain-mlogloss:0.52106\ttest-mlogloss:0.577608\n",
      "[157]\ttrain-mlogloss:0.520388\ttest-mlogloss:0.577363\n",
      "[158]\ttrain-mlogloss:0.519937\ttest-mlogloss:0.577104\n",
      "[159]\ttrain-mlogloss:0.519286\ttest-mlogloss:0.576897\n",
      "[160]\ttrain-mlogloss:0.518808\ttest-mlogloss:0.576722\n",
      "[161]\ttrain-mlogloss:0.518141\ttest-mlogloss:0.576384\n",
      "[162]\ttrain-mlogloss:0.517603\ttest-mlogloss:0.576177\n",
      "[163]\ttrain-mlogloss:0.517379\ttest-mlogloss:0.57609\n",
      "[164]\ttrain-mlogloss:0.516763\ttest-mlogloss:0.575854\n",
      "[165]\ttrain-mlogloss:0.516167\ttest-mlogloss:0.575577\n",
      "[166]\ttrain-mlogloss:0.515572\ttest-mlogloss:0.575319\n",
      "[167]\ttrain-mlogloss:0.514827\ttest-mlogloss:0.575048\n",
      "[168]\ttrain-mlogloss:0.514247\ttest-mlogloss:0.574761\n",
      "[169]\ttrain-mlogloss:0.513736\ttest-mlogloss:0.574516\n",
      "[170]\ttrain-mlogloss:0.513241\ttest-mlogloss:0.574316\n",
      "[171]\ttrain-mlogloss:0.512747\ttest-mlogloss:0.574088\n",
      "[172]\ttrain-mlogloss:0.51215\ttest-mlogloss:0.573769\n",
      "[173]\ttrain-mlogloss:0.511567\ttest-mlogloss:0.573555\n",
      "[174]\ttrain-mlogloss:0.511111\ttest-mlogloss:0.573347\n",
      "[175]\ttrain-mlogloss:0.510628\ttest-mlogloss:0.573164\n",
      "[176]\ttrain-mlogloss:0.510228\ttest-mlogloss:0.573003\n",
      "[177]\ttrain-mlogloss:0.509756\ttest-mlogloss:0.572806\n",
      "[178]\ttrain-mlogloss:0.509287\ttest-mlogloss:0.572596\n",
      "[179]\ttrain-mlogloss:0.508763\ttest-mlogloss:0.572377\n",
      "[180]\ttrain-mlogloss:0.508118\ttest-mlogloss:0.57208\n",
      "[181]\ttrain-mlogloss:0.507731\ttest-mlogloss:0.571894\n",
      "[182]\ttrain-mlogloss:0.507284\ttest-mlogloss:0.571675\n",
      "[183]\ttrain-mlogloss:0.506835\ttest-mlogloss:0.571483\n",
      "[184]\ttrain-mlogloss:0.506459\ttest-mlogloss:0.571296\n",
      "[185]\ttrain-mlogloss:0.505915\ttest-mlogloss:0.571062\n",
      "[186]\ttrain-mlogloss:0.505463\ttest-mlogloss:0.570876\n",
      "[187]\ttrain-mlogloss:0.504991\ttest-mlogloss:0.570742\n",
      "[188]\ttrain-mlogloss:0.504477\ttest-mlogloss:0.570496\n",
      "[189]\ttrain-mlogloss:0.504091\ttest-mlogloss:0.570389\n",
      "[190]\ttrain-mlogloss:0.503428\ttest-mlogloss:0.570099\n",
      "[191]\ttrain-mlogloss:0.502948\ttest-mlogloss:0.56997\n",
      "[192]\ttrain-mlogloss:0.502649\ttest-mlogloss:0.569842\n",
      "[193]\ttrain-mlogloss:0.502368\ttest-mlogloss:0.569716\n",
      "[194]\ttrain-mlogloss:0.502015\ttest-mlogloss:0.569628\n",
      "[195]\ttrain-mlogloss:0.501587\ttest-mlogloss:0.56948\n",
      "[196]\ttrain-mlogloss:0.501184\ttest-mlogloss:0.569317\n",
      "[197]\ttrain-mlogloss:0.500765\ttest-mlogloss:0.569135\n",
      "[198]\ttrain-mlogloss:0.500305\ttest-mlogloss:0.569026\n",
      "[199]\ttrain-mlogloss:0.499881\ttest-mlogloss:0.568846\n",
      "[200]\ttrain-mlogloss:0.499565\ttest-mlogloss:0.568703\n",
      "[201]\ttrain-mlogloss:0.499177\ttest-mlogloss:0.568592\n",
      "[202]\ttrain-mlogloss:0.498796\ttest-mlogloss:0.568519\n",
      "[203]\ttrain-mlogloss:0.498305\ttest-mlogloss:0.568383\n",
      "[204]\ttrain-mlogloss:0.497962\ttest-mlogloss:0.568293\n",
      "[205]\ttrain-mlogloss:0.497506\ttest-mlogloss:0.56814\n",
      "[206]\ttrain-mlogloss:0.497047\ttest-mlogloss:0.568029\n",
      "[207]\ttrain-mlogloss:0.496683\ttest-mlogloss:0.567925\n",
      "[208]\ttrain-mlogloss:0.496321\ttest-mlogloss:0.567774\n",
      "[209]\ttrain-mlogloss:0.495974\ttest-mlogloss:0.567725\n",
      "[210]\ttrain-mlogloss:0.495621\ttest-mlogloss:0.56767\n",
      "[211]\ttrain-mlogloss:0.495113\ttest-mlogloss:0.567486\n",
      "[212]\ttrain-mlogloss:0.494614\ttest-mlogloss:0.567337\n",
      "[213]\ttrain-mlogloss:0.494071\ttest-mlogloss:0.567135\n",
      "[214]\ttrain-mlogloss:0.493646\ttest-mlogloss:0.566961\n",
      "[215]\ttrain-mlogloss:0.493262\ttest-mlogloss:0.566896\n",
      "[216]\ttrain-mlogloss:0.492916\ttest-mlogloss:0.566738\n",
      "[217]\ttrain-mlogloss:0.492599\ttest-mlogloss:0.566656\n",
      "[218]\ttrain-mlogloss:0.492138\ttest-mlogloss:0.566499\n",
      "[219]\ttrain-mlogloss:0.4917\ttest-mlogloss:0.566391\n",
      "[220]\ttrain-mlogloss:0.491201\ttest-mlogloss:0.566121\n",
      "[221]\ttrain-mlogloss:0.490611\ttest-mlogloss:0.565882\n",
      "[222]\ttrain-mlogloss:0.490192\ttest-mlogloss:0.565709\n",
      "[223]\ttrain-mlogloss:0.489865\ttest-mlogloss:0.565595\n",
      "[224]\ttrain-mlogloss:0.489428\ttest-mlogloss:0.565421\n",
      "[225]\ttrain-mlogloss:0.488882\ttest-mlogloss:0.565246\n",
      "[226]\ttrain-mlogloss:0.488447\ttest-mlogloss:0.56514\n",
      "[227]\ttrain-mlogloss:0.488139\ttest-mlogloss:0.565041\n",
      "[228]\ttrain-mlogloss:0.487706\ttest-mlogloss:0.564872\n",
      "[229]\ttrain-mlogloss:0.48712\ttest-mlogloss:0.564798\n",
      "[230]\ttrain-mlogloss:0.486694\ttest-mlogloss:0.56462\n",
      "[231]\ttrain-mlogloss:0.486329\ttest-mlogloss:0.564507\n",
      "[232]\ttrain-mlogloss:0.485926\ttest-mlogloss:0.56441\n",
      "[233]\ttrain-mlogloss:0.485612\ttest-mlogloss:0.564283\n",
      "[234]\ttrain-mlogloss:0.485258\ttest-mlogloss:0.564146\n",
      "[235]\ttrain-mlogloss:0.48491\ttest-mlogloss:0.56403\n",
      "[236]\ttrain-mlogloss:0.48452\ttest-mlogloss:0.563938\n",
      "[237]\ttrain-mlogloss:0.484007\ttest-mlogloss:0.56371\n",
      "[238]\ttrain-mlogloss:0.483666\ttest-mlogloss:0.563637\n",
      "[239]\ttrain-mlogloss:0.483225\ttest-mlogloss:0.563596\n",
      "[240]\ttrain-mlogloss:0.482948\ttest-mlogloss:0.563497\n",
      "[241]\ttrain-mlogloss:0.482701\ttest-mlogloss:0.563431\n",
      "[242]\ttrain-mlogloss:0.482419\ttest-mlogloss:0.563316\n",
      "[243]\ttrain-mlogloss:0.482062\ttest-mlogloss:0.563251\n",
      "[244]\ttrain-mlogloss:0.481676\ttest-mlogloss:0.563152\n",
      "[245]\ttrain-mlogloss:0.481323\ttest-mlogloss:0.563064\n",
      "[246]\ttrain-mlogloss:0.481147\ttest-mlogloss:0.563025\n",
      "[247]\ttrain-mlogloss:0.480672\ttest-mlogloss:0.562939\n",
      "[248]\ttrain-mlogloss:0.480472\ttest-mlogloss:0.562858\n",
      "[249]\ttrain-mlogloss:0.480131\ttest-mlogloss:0.562751\n",
      "[250]\ttrain-mlogloss:0.479745\ttest-mlogloss:0.562735\n",
      "[251]\ttrain-mlogloss:0.479351\ttest-mlogloss:0.562634\n",
      "[252]\ttrain-mlogloss:0.479018\ttest-mlogloss:0.562543\n",
      "[253]\ttrain-mlogloss:0.478639\ttest-mlogloss:0.562412\n",
      "[254]\ttrain-mlogloss:0.478536\ttest-mlogloss:0.562355\n",
      "[255]\ttrain-mlogloss:0.47807\ttest-mlogloss:0.562277\n",
      "[256]\ttrain-mlogloss:0.477693\ttest-mlogloss:0.562216\n",
      "[257]\ttrain-mlogloss:0.477376\ttest-mlogloss:0.562074\n",
      "[258]\ttrain-mlogloss:0.47687\ttest-mlogloss:0.561957\n",
      "[259]\ttrain-mlogloss:0.476514\ttest-mlogloss:0.561806\n",
      "[260]\ttrain-mlogloss:0.476181\ttest-mlogloss:0.561766\n",
      "[261]\ttrain-mlogloss:0.47584\ttest-mlogloss:0.561713\n",
      "[262]\ttrain-mlogloss:0.475372\ttest-mlogloss:0.561658\n",
      "[263]\ttrain-mlogloss:0.474976\ttest-mlogloss:0.561564\n",
      "[264]\ttrain-mlogloss:0.474635\ttest-mlogloss:0.561488\n",
      "[265]\ttrain-mlogloss:0.474286\ttest-mlogloss:0.561404\n",
      "[266]\ttrain-mlogloss:0.473901\ttest-mlogloss:0.561382\n",
      "[267]\ttrain-mlogloss:0.47353\ttest-mlogloss:0.561309\n",
      "[268]\ttrain-mlogloss:0.473091\ttest-mlogloss:0.56128\n",
      "[269]\ttrain-mlogloss:0.472862\ttest-mlogloss:0.561177\n",
      "[270]\ttrain-mlogloss:0.472466\ttest-mlogloss:0.561071\n",
      "[271]\ttrain-mlogloss:0.472168\ttest-mlogloss:0.560993\n",
      "[272]\ttrain-mlogloss:0.471843\ttest-mlogloss:0.560938\n",
      "[273]\ttrain-mlogloss:0.47134\ttest-mlogloss:0.560815\n",
      "[274]\ttrain-mlogloss:0.470838\ttest-mlogloss:0.56075\n",
      "[275]\ttrain-mlogloss:0.470476\ttest-mlogloss:0.560665\n",
      "[276]\ttrain-mlogloss:0.470218\ttest-mlogloss:0.560618\n",
      "[277]\ttrain-mlogloss:0.469982\ttest-mlogloss:0.560569\n",
      "[278]\ttrain-mlogloss:0.469772\ttest-mlogloss:0.560498\n",
      "[279]\ttrain-mlogloss:0.469366\ttest-mlogloss:0.56048\n",
      "[280]\ttrain-mlogloss:0.468978\ttest-mlogloss:0.560396\n",
      "[281]\ttrain-mlogloss:0.468511\ttest-mlogloss:0.5603\n",
      "[282]\ttrain-mlogloss:0.468227\ttest-mlogloss:0.560274\n",
      "[283]\ttrain-mlogloss:0.468019\ttest-mlogloss:0.560206\n",
      "[284]\ttrain-mlogloss:0.467631\ttest-mlogloss:0.560133\n",
      "[285]\ttrain-mlogloss:0.467332\ttest-mlogloss:0.560078\n",
      "[286]\ttrain-mlogloss:0.467099\ttest-mlogloss:0.559994\n",
      "[287]\ttrain-mlogloss:0.466719\ttest-mlogloss:0.559962\n",
      "[288]\ttrain-mlogloss:0.466356\ttest-mlogloss:0.559818\n",
      "[289]\ttrain-mlogloss:0.466048\ttest-mlogloss:0.55973\n",
      "[290]\ttrain-mlogloss:0.465561\ttest-mlogloss:0.559715\n",
      "[291]\ttrain-mlogloss:0.465167\ttest-mlogloss:0.559636\n",
      "[292]\ttrain-mlogloss:0.464955\ttest-mlogloss:0.559621\n",
      "[293]\ttrain-mlogloss:0.464733\ttest-mlogloss:0.559568\n",
      "[294]\ttrain-mlogloss:0.464507\ttest-mlogloss:0.559455\n",
      "[295]\ttrain-mlogloss:0.464279\ttest-mlogloss:0.559442\n",
      "[296]\ttrain-mlogloss:0.463956\ttest-mlogloss:0.559385\n",
      "[297]\ttrain-mlogloss:0.463607\ttest-mlogloss:0.559338\n",
      "[298]\ttrain-mlogloss:0.463336\ttest-mlogloss:0.559308\n",
      "[299]\ttrain-mlogloss:0.462884\ttest-mlogloss:0.559262\n",
      "[300]\ttrain-mlogloss:0.462689\ttest-mlogloss:0.559217\n",
      "[301]\ttrain-mlogloss:0.46245\ttest-mlogloss:0.559143\n",
      "[302]\ttrain-mlogloss:0.462041\ttest-mlogloss:0.559093\n",
      "[303]\ttrain-mlogloss:0.461759\ttest-mlogloss:0.559051\n",
      "[304]\ttrain-mlogloss:0.461474\ttest-mlogloss:0.55903\n",
      "[305]\ttrain-mlogloss:0.46119\ttest-mlogloss:0.558931\n",
      "[306]\ttrain-mlogloss:0.460797\ttest-mlogloss:0.558839\n",
      "[307]\ttrain-mlogloss:0.460455\ttest-mlogloss:0.55879\n",
      "[308]\ttrain-mlogloss:0.460069\ttest-mlogloss:0.558659\n",
      "[309]\ttrain-mlogloss:0.459862\ttest-mlogloss:0.55864\n",
      "[310]\ttrain-mlogloss:0.459603\ttest-mlogloss:0.55856\n",
      "[311]\ttrain-mlogloss:0.459202\ttest-mlogloss:0.558452\n",
      "[312]\ttrain-mlogloss:0.458953\ttest-mlogloss:0.558429\n",
      "[313]\ttrain-mlogloss:0.458639\ttest-mlogloss:0.558388\n",
      "[314]\ttrain-mlogloss:0.458458\ttest-mlogloss:0.558354\n",
      "[315]\ttrain-mlogloss:0.458223\ttest-mlogloss:0.558343\n",
      "[316]\ttrain-mlogloss:0.457963\ttest-mlogloss:0.558332\n",
      "[317]\ttrain-mlogloss:0.457605\ttest-mlogloss:0.55829\n",
      "[318]\ttrain-mlogloss:0.45721\ttest-mlogloss:0.558181\n",
      "[319]\ttrain-mlogloss:0.456802\ttest-mlogloss:0.558087\n",
      "[320]\ttrain-mlogloss:0.456432\ttest-mlogloss:0.558007\n",
      "[321]\ttrain-mlogloss:0.456153\ttest-mlogloss:0.557932\n",
      "[322]\ttrain-mlogloss:0.455847\ttest-mlogloss:0.557892\n",
      "[323]\ttrain-mlogloss:0.455508\ttest-mlogloss:0.557809\n",
      "[324]\ttrain-mlogloss:0.455279\ttest-mlogloss:0.557773\n",
      "[325]\ttrain-mlogloss:0.455152\ttest-mlogloss:0.557726\n",
      "[326]\ttrain-mlogloss:0.454983\ttest-mlogloss:0.55767\n",
      "[327]\ttrain-mlogloss:0.454715\ttest-mlogloss:0.557603\n",
      "[328]\ttrain-mlogloss:0.454465\ttest-mlogloss:0.557558\n",
      "[329]\ttrain-mlogloss:0.454113\ttest-mlogloss:0.557499\n",
      "[330]\ttrain-mlogloss:0.453951\ttest-mlogloss:0.557496\n",
      "[331]\ttrain-mlogloss:0.45374\ttest-mlogloss:0.557477\n",
      "[332]\ttrain-mlogloss:0.453473\ttest-mlogloss:0.55741\n",
      "[333]\ttrain-mlogloss:0.453102\ttest-mlogloss:0.557401\n",
      "[334]\ttrain-mlogloss:0.45265\ttest-mlogloss:0.557348\n",
      "[335]\ttrain-mlogloss:0.452397\ttest-mlogloss:0.557348\n",
      "[336]\ttrain-mlogloss:0.45223\ttest-mlogloss:0.557303\n",
      "[337]\ttrain-mlogloss:0.451983\ttest-mlogloss:0.557283\n",
      "[338]\ttrain-mlogloss:0.45175\ttest-mlogloss:0.557268\n",
      "[339]\ttrain-mlogloss:0.451577\ttest-mlogloss:0.557221\n",
      "[340]\ttrain-mlogloss:0.451285\ttest-mlogloss:0.557195\n",
      "[341]\ttrain-mlogloss:0.451122\ttest-mlogloss:0.557158\n",
      "[342]\ttrain-mlogloss:0.450858\ttest-mlogloss:0.557135\n",
      "[343]\ttrain-mlogloss:0.45053\ttest-mlogloss:0.557076\n",
      "[344]\ttrain-mlogloss:0.450294\ttest-mlogloss:0.557036\n",
      "[345]\ttrain-mlogloss:0.449938\ttest-mlogloss:0.557009\n",
      "[346]\ttrain-mlogloss:0.449684\ttest-mlogloss:0.556946\n",
      "[347]\ttrain-mlogloss:0.449372\ttest-mlogloss:0.556841\n",
      "[348]\ttrain-mlogloss:0.449117\ttest-mlogloss:0.556795\n",
      "[349]\ttrain-mlogloss:0.448855\ttest-mlogloss:0.5568\n",
      "[350]\ttrain-mlogloss:0.448609\ttest-mlogloss:0.556773\n",
      "[351]\ttrain-mlogloss:0.448329\ttest-mlogloss:0.5567\n",
      "[352]\ttrain-mlogloss:0.447997\ttest-mlogloss:0.556596\n",
      "[353]\ttrain-mlogloss:0.447645\ttest-mlogloss:0.556503\n",
      "[354]\ttrain-mlogloss:0.447408\ttest-mlogloss:0.556484\n",
      "[355]\ttrain-mlogloss:0.447073\ttest-mlogloss:0.556452\n",
      "[356]\ttrain-mlogloss:0.44675\ttest-mlogloss:0.556446\n",
      "[357]\ttrain-mlogloss:0.446539\ttest-mlogloss:0.556423\n",
      "[358]\ttrain-mlogloss:0.446375\ttest-mlogloss:0.556402\n",
      "[359]\ttrain-mlogloss:0.446073\ttest-mlogloss:0.556405\n",
      "[360]\ttrain-mlogloss:0.445728\ttest-mlogloss:0.556396\n",
      "[361]\ttrain-mlogloss:0.445467\ttest-mlogloss:0.556399\n",
      "[362]\ttrain-mlogloss:0.44522\ttest-mlogloss:0.556383\n",
      "[363]\ttrain-mlogloss:0.445023\ttest-mlogloss:0.556317\n",
      "[364]\ttrain-mlogloss:0.444716\ttest-mlogloss:0.556297\n",
      "[365]\ttrain-mlogloss:0.444516\ttest-mlogloss:0.556315\n",
      "[366]\ttrain-mlogloss:0.444313\ttest-mlogloss:0.55627\n",
      "[367]\ttrain-mlogloss:0.443982\ttest-mlogloss:0.556215\n",
      "[368]\ttrain-mlogloss:0.443529\ttest-mlogloss:0.556146\n",
      "[369]\ttrain-mlogloss:0.44315\ttest-mlogloss:0.556128\n",
      "[370]\ttrain-mlogloss:0.442848\ttest-mlogloss:0.556097\n",
      "[371]\ttrain-mlogloss:0.442751\ttest-mlogloss:0.55608\n",
      "[372]\ttrain-mlogloss:0.442513\ttest-mlogloss:0.556061\n",
      "[373]\ttrain-mlogloss:0.442297\ttest-mlogloss:0.556036\n",
      "[374]\ttrain-mlogloss:0.442003\ttest-mlogloss:0.55599\n",
      "[375]\ttrain-mlogloss:0.441765\ttest-mlogloss:0.555959\n",
      "[376]\ttrain-mlogloss:0.441423\ttest-mlogloss:0.555845\n",
      "[377]\ttrain-mlogloss:0.441321\ttest-mlogloss:0.555819\n",
      "[378]\ttrain-mlogloss:0.441141\ttest-mlogloss:0.555765\n",
      "[379]\ttrain-mlogloss:0.44098\ttest-mlogloss:0.555726\n",
      "[380]\ttrain-mlogloss:0.440651\ttest-mlogloss:0.555657\n",
      "[381]\ttrain-mlogloss:0.440257\ttest-mlogloss:0.555603\n",
      "[382]\ttrain-mlogloss:0.439984\ttest-mlogloss:0.555547\n",
      "[383]\ttrain-mlogloss:0.4398\ttest-mlogloss:0.555504\n",
      "[384]\ttrain-mlogloss:0.439576\ttest-mlogloss:0.555477\n",
      "[385]\ttrain-mlogloss:0.439191\ttest-mlogloss:0.555428\n",
      "[386]\ttrain-mlogloss:0.439058\ttest-mlogloss:0.55538\n",
      "[387]\ttrain-mlogloss:0.438678\ttest-mlogloss:0.555322\n",
      "[388]\ttrain-mlogloss:0.438447\ttest-mlogloss:0.555316\n",
      "[389]\ttrain-mlogloss:0.438269\ttest-mlogloss:0.555271\n",
      "[390]\ttrain-mlogloss:0.437948\ttest-mlogloss:0.555246\n",
      "[391]\ttrain-mlogloss:0.4378\ttest-mlogloss:0.555226\n",
      "[392]\ttrain-mlogloss:0.437619\ttest-mlogloss:0.555153\n",
      "[393]\ttrain-mlogloss:0.437492\ttest-mlogloss:0.55513\n",
      "[394]\ttrain-mlogloss:0.437305\ttest-mlogloss:0.555073\n",
      "[395]\ttrain-mlogloss:0.437107\ttest-mlogloss:0.555046\n",
      "[396]\ttrain-mlogloss:0.436844\ttest-mlogloss:0.554997\n",
      "[397]\ttrain-mlogloss:0.436606\ttest-mlogloss:0.554973\n",
      "[398]\ttrain-mlogloss:0.436435\ttest-mlogloss:0.554952\n",
      "[399]\ttrain-mlogloss:0.436242\ttest-mlogloss:0.554948\n",
      "[400]\ttrain-mlogloss:0.43593\ttest-mlogloss:0.554922\n",
      "[401]\ttrain-mlogloss:0.435695\ttest-mlogloss:0.554854\n",
      "[402]\ttrain-mlogloss:0.435503\ttest-mlogloss:0.554836\n",
      "[403]\ttrain-mlogloss:0.435272\ttest-mlogloss:0.554815\n",
      "[404]\ttrain-mlogloss:0.434882\ttest-mlogloss:0.554767\n",
      "[405]\ttrain-mlogloss:0.434634\ttest-mlogloss:0.554696\n",
      "[406]\ttrain-mlogloss:0.434246\ttest-mlogloss:0.55464\n",
      "[407]\ttrain-mlogloss:0.434081\ttest-mlogloss:0.554608\n",
      "[408]\ttrain-mlogloss:0.433945\ttest-mlogloss:0.554582\n",
      "[409]\ttrain-mlogloss:0.433745\ttest-mlogloss:0.554533\n",
      "[410]\ttrain-mlogloss:0.433605\ttest-mlogloss:0.554491\n",
      "[411]\ttrain-mlogloss:0.433451\ttest-mlogloss:0.554482\n",
      "[412]\ttrain-mlogloss:0.433188\ttest-mlogloss:0.554475\n",
      "[413]\ttrain-mlogloss:0.432979\ttest-mlogloss:0.554435\n",
      "[414]\ttrain-mlogloss:0.432647\ttest-mlogloss:0.554382\n",
      "[415]\ttrain-mlogloss:0.432402\ttest-mlogloss:0.55436\n",
      "[416]\ttrain-mlogloss:0.432209\ttest-mlogloss:0.554316\n",
      "[417]\ttrain-mlogloss:0.432122\ttest-mlogloss:0.554248\n",
      "[418]\ttrain-mlogloss:0.431764\ttest-mlogloss:0.554221\n",
      "[419]\ttrain-mlogloss:0.431629\ttest-mlogloss:0.554207\n",
      "[420]\ttrain-mlogloss:0.43152\ttest-mlogloss:0.554207\n",
      "[421]\ttrain-mlogloss:0.431337\ttest-mlogloss:0.554157\n",
      "[422]\ttrain-mlogloss:0.4312\ttest-mlogloss:0.554151\n",
      "[423]\ttrain-mlogloss:0.430988\ttest-mlogloss:0.554144\n",
      "[424]\ttrain-mlogloss:0.430791\ttest-mlogloss:0.554136\n",
      "[425]\ttrain-mlogloss:0.430584\ttest-mlogloss:0.554094\n",
      "[426]\ttrain-mlogloss:0.430386\ttest-mlogloss:0.554082\n",
      "[427]\ttrain-mlogloss:0.430131\ttest-mlogloss:0.55403\n",
      "[428]\ttrain-mlogloss:0.429781\ttest-mlogloss:0.554\n",
      "[429]\ttrain-mlogloss:0.42948\ttest-mlogloss:0.553938\n",
      "[430]\ttrain-mlogloss:0.429284\ttest-mlogloss:0.553917\n",
      "[431]\ttrain-mlogloss:0.429182\ttest-mlogloss:0.55388\n",
      "[432]\ttrain-mlogloss:0.428929\ttest-mlogloss:0.553867\n",
      "[433]\ttrain-mlogloss:0.428706\ttest-mlogloss:0.553824\n",
      "[434]\ttrain-mlogloss:0.428554\ttest-mlogloss:0.553792\n",
      "[435]\ttrain-mlogloss:0.428342\ttest-mlogloss:0.553781\n",
      "[436]\ttrain-mlogloss:0.428082\ttest-mlogloss:0.55378\n",
      "[437]\ttrain-mlogloss:0.427821\ttest-mlogloss:0.55374\n",
      "[438]\ttrain-mlogloss:0.427638\ttest-mlogloss:0.553739\n",
      "[439]\ttrain-mlogloss:0.427427\ttest-mlogloss:0.553693\n",
      "[440]\ttrain-mlogloss:0.427251\ttest-mlogloss:0.553664\n",
      "[441]\ttrain-mlogloss:0.42717\ttest-mlogloss:0.553663\n",
      "[442]\ttrain-mlogloss:0.426847\ttest-mlogloss:0.553629\n",
      "[443]\ttrain-mlogloss:0.426553\ttest-mlogloss:0.553576\n",
      "[444]\ttrain-mlogloss:0.426395\ttest-mlogloss:0.553557\n",
      "[445]\ttrain-mlogloss:0.426209\ttest-mlogloss:0.553494\n",
      "[446]\ttrain-mlogloss:0.425891\ttest-mlogloss:0.553464\n",
      "[447]\ttrain-mlogloss:0.425555\ttest-mlogloss:0.553443\n",
      "[448]\ttrain-mlogloss:0.425365\ttest-mlogloss:0.553391\n",
      "[449]\ttrain-mlogloss:0.425067\ttest-mlogloss:0.553363\n",
      "[450]\ttrain-mlogloss:0.424747\ttest-mlogloss:0.55332\n",
      "[451]\ttrain-mlogloss:0.424627\ttest-mlogloss:0.553285\n",
      "[452]\ttrain-mlogloss:0.424418\ttest-mlogloss:0.553252\n",
      "[453]\ttrain-mlogloss:0.424162\ttest-mlogloss:0.553203\n",
      "[454]\ttrain-mlogloss:0.423967\ttest-mlogloss:0.553155\n",
      "[455]\ttrain-mlogloss:0.423819\ttest-mlogloss:0.553119\n",
      "[456]\ttrain-mlogloss:0.423604\ttest-mlogloss:0.553131\n",
      "[457]\ttrain-mlogloss:0.423488\ttest-mlogloss:0.553109\n",
      "[458]\ttrain-mlogloss:0.423277\ttest-mlogloss:0.553062\n",
      "[459]\ttrain-mlogloss:0.423049\ttest-mlogloss:0.553042\n",
      "[460]\ttrain-mlogloss:0.422886\ttest-mlogloss:0.553041\n",
      "[461]\ttrain-mlogloss:0.422671\ttest-mlogloss:0.553049\n",
      "[462]\ttrain-mlogloss:0.422454\ttest-mlogloss:0.553054\n",
      "[463]\ttrain-mlogloss:0.422441\ttest-mlogloss:0.553065\n",
      "[464]\ttrain-mlogloss:0.42219\ttest-mlogloss:0.553024\n",
      "[465]\ttrain-mlogloss:0.422004\ttest-mlogloss:0.552989\n",
      "[466]\ttrain-mlogloss:0.421804\ttest-mlogloss:0.552925\n",
      "[467]\ttrain-mlogloss:0.421629\ttest-mlogloss:0.552929\n",
      "[468]\ttrain-mlogloss:0.421477\ttest-mlogloss:0.552905\n",
      "[469]\ttrain-mlogloss:0.421253\ttest-mlogloss:0.552859\n",
      "[470]\ttrain-mlogloss:0.421012\ttest-mlogloss:0.552813\n",
      "[471]\ttrain-mlogloss:0.420715\ttest-mlogloss:0.552782\n",
      "[472]\ttrain-mlogloss:0.420525\ttest-mlogloss:0.552786\n",
      "[473]\ttrain-mlogloss:0.420196\ttest-mlogloss:0.552799\n",
      "[474]\ttrain-mlogloss:0.420025\ttest-mlogloss:0.552748\n",
      "[475]\ttrain-mlogloss:0.419858\ttest-mlogloss:0.552721\n",
      "[476]\ttrain-mlogloss:0.41965\ttest-mlogloss:0.552718\n",
      "[477]\ttrain-mlogloss:0.41943\ttest-mlogloss:0.5527\n",
      "[478]\ttrain-mlogloss:0.419228\ttest-mlogloss:0.552679\n",
      "[479]\ttrain-mlogloss:0.419034\ttest-mlogloss:0.552685\n",
      "[480]\ttrain-mlogloss:0.418898\ttest-mlogloss:0.55268\n",
      "[481]\ttrain-mlogloss:0.418733\ttest-mlogloss:0.552624\n",
      "[482]\ttrain-mlogloss:0.418606\ttest-mlogloss:0.552591\n",
      "[483]\ttrain-mlogloss:0.418274\ttest-mlogloss:0.552582\n",
      "[484]\ttrain-mlogloss:0.418117\ttest-mlogloss:0.552584\n",
      "[485]\ttrain-mlogloss:0.417961\ttest-mlogloss:0.55253\n",
      "[486]\ttrain-mlogloss:0.417753\ttest-mlogloss:0.552518\n",
      "[487]\ttrain-mlogloss:0.417548\ttest-mlogloss:0.552479\n",
      "[488]\ttrain-mlogloss:0.417406\ttest-mlogloss:0.552447\n",
      "[489]\ttrain-mlogloss:0.417123\ttest-mlogloss:0.552395\n",
      "[490]\ttrain-mlogloss:0.416884\ttest-mlogloss:0.552373\n",
      "[491]\ttrain-mlogloss:0.416792\ttest-mlogloss:0.552364\n",
      "[492]\ttrain-mlogloss:0.416537\ttest-mlogloss:0.552326\n",
      "[493]\ttrain-mlogloss:0.416396\ttest-mlogloss:0.552275\n",
      "[494]\ttrain-mlogloss:0.416254\ttest-mlogloss:0.552233\n",
      "[495]\ttrain-mlogloss:0.41618\ttest-mlogloss:0.552234\n",
      "[496]\ttrain-mlogloss:0.415928\ttest-mlogloss:0.552208\n",
      "[497]\ttrain-mlogloss:0.415707\ttest-mlogloss:0.552139\n",
      "[498]\ttrain-mlogloss:0.41551\ttest-mlogloss:0.552126\n",
      "[499]\ttrain-mlogloss:0.415336\ttest-mlogloss:0.55212\n",
      "[500]\ttrain-mlogloss:0.415181\ttest-mlogloss:0.552102\n",
      "[501]\ttrain-mlogloss:0.415041\ttest-mlogloss:0.552099\n",
      "[502]\ttrain-mlogloss:0.414989\ttest-mlogloss:0.552073\n",
      "[503]\ttrain-mlogloss:0.414861\ttest-mlogloss:0.552101\n",
      "[504]\ttrain-mlogloss:0.414622\ttest-mlogloss:0.55207\n",
      "[505]\ttrain-mlogloss:0.414443\ttest-mlogloss:0.552023\n",
      "[506]\ttrain-mlogloss:0.414245\ttest-mlogloss:0.551982\n",
      "[507]\ttrain-mlogloss:0.414133\ttest-mlogloss:0.551963\n",
      "[508]\ttrain-mlogloss:0.413962\ttest-mlogloss:0.551914\n",
      "[509]\ttrain-mlogloss:0.413817\ttest-mlogloss:0.551932\n",
      "[510]\ttrain-mlogloss:0.413817\ttest-mlogloss:0.551932\n",
      "[511]\ttrain-mlogloss:0.413509\ttest-mlogloss:0.551896\n",
      "[512]\ttrain-mlogloss:0.413366\ttest-mlogloss:0.551862\n",
      "[513]\ttrain-mlogloss:0.413106\ttest-mlogloss:0.551836\n",
      "[514]\ttrain-mlogloss:0.412933\ttest-mlogloss:0.551804\n",
      "[515]\ttrain-mlogloss:0.412676\ttest-mlogloss:0.551778\n",
      "[516]\ttrain-mlogloss:0.412408\ttest-mlogloss:0.551732\n",
      "[517]\ttrain-mlogloss:0.412203\ttest-mlogloss:0.551715\n",
      "[518]\ttrain-mlogloss:0.412067\ttest-mlogloss:0.551705\n",
      "[519]\ttrain-mlogloss:0.411803\ttest-mlogloss:0.551735\n",
      "[520]\ttrain-mlogloss:0.411622\ttest-mlogloss:0.55171\n",
      "[521]\ttrain-mlogloss:0.411507\ttest-mlogloss:0.551695\n",
      "[522]\ttrain-mlogloss:0.411461\ttest-mlogloss:0.551689\n",
      "[523]\ttrain-mlogloss:0.411369\ttest-mlogloss:0.551669\n",
      "[524]\ttrain-mlogloss:0.411247\ttest-mlogloss:0.55169\n",
      "[525]\ttrain-mlogloss:0.41112\ttest-mlogloss:0.551686\n",
      "[526]\ttrain-mlogloss:0.410864\ttest-mlogloss:0.55169\n",
      "[527]\ttrain-mlogloss:0.410706\ttest-mlogloss:0.551674\n",
      "[528]\ttrain-mlogloss:0.410603\ttest-mlogloss:0.551693\n",
      "[529]\ttrain-mlogloss:0.410505\ttest-mlogloss:0.551653\n",
      "[530]\ttrain-mlogloss:0.410197\ttest-mlogloss:0.551629\n",
      "[531]\ttrain-mlogloss:0.410086\ttest-mlogloss:0.551612\n",
      "[532]\ttrain-mlogloss:0.409967\ttest-mlogloss:0.551594\n",
      "[533]\ttrain-mlogloss:0.409835\ttest-mlogloss:0.551557\n",
      "[534]\ttrain-mlogloss:0.409664\ttest-mlogloss:0.551546\n",
      "[535]\ttrain-mlogloss:0.409488\ttest-mlogloss:0.551569\n",
      "[536]\ttrain-mlogloss:0.409357\ttest-mlogloss:0.55155\n",
      "[537]\ttrain-mlogloss:0.409071\ttest-mlogloss:0.551567\n",
      "[538]\ttrain-mlogloss:0.408911\ttest-mlogloss:0.55154\n",
      "[539]\ttrain-mlogloss:0.408743\ttest-mlogloss:0.551533\n",
      "[540]\ttrain-mlogloss:0.40845\ttest-mlogloss:0.551532\n",
      "[541]\ttrain-mlogloss:0.408312\ttest-mlogloss:0.551474\n",
      "[542]\ttrain-mlogloss:0.408137\ttest-mlogloss:0.551457\n",
      "[543]\ttrain-mlogloss:0.407944\ttest-mlogloss:0.551457\n",
      "[544]\ttrain-mlogloss:0.407754\ttest-mlogloss:0.551408\n",
      "[545]\ttrain-mlogloss:0.40748\ttest-mlogloss:0.551391\n",
      "[546]\ttrain-mlogloss:0.40734\ttest-mlogloss:0.551376\n",
      "[547]\ttrain-mlogloss:0.407147\ttest-mlogloss:0.551365\n",
      "[548]\ttrain-mlogloss:0.406905\ttest-mlogloss:0.551343\n",
      "[549]\ttrain-mlogloss:0.406686\ttest-mlogloss:0.551371\n",
      "[550]\ttrain-mlogloss:0.406577\ttest-mlogloss:0.551331\n",
      "[551]\ttrain-mlogloss:0.406572\ttest-mlogloss:0.551323\n",
      "[552]\ttrain-mlogloss:0.406375\ttest-mlogloss:0.5513\n",
      "[553]\ttrain-mlogloss:0.406233\ttest-mlogloss:0.55126\n",
      "[554]\ttrain-mlogloss:0.405925\ttest-mlogloss:0.551268\n",
      "[555]\ttrain-mlogloss:0.405763\ttest-mlogloss:0.551286\n",
      "[556]\ttrain-mlogloss:0.405633\ttest-mlogloss:0.551256\n",
      "[557]\ttrain-mlogloss:0.405413\ttest-mlogloss:0.55121\n",
      "[558]\ttrain-mlogloss:0.405224\ttest-mlogloss:0.55121\n",
      "[559]\ttrain-mlogloss:0.405019\ttest-mlogloss:0.551174\n",
      "[560]\ttrain-mlogloss:0.4049\ttest-mlogloss:0.551169\n",
      "[561]\ttrain-mlogloss:0.404807\ttest-mlogloss:0.551147\n",
      "[562]\ttrain-mlogloss:0.40469\ttest-mlogloss:0.551136\n",
      "[563]\ttrain-mlogloss:0.404653\ttest-mlogloss:0.551128\n",
      "[564]\ttrain-mlogloss:0.4045\ttest-mlogloss:0.551126\n",
      "[565]\ttrain-mlogloss:0.404196\ttest-mlogloss:0.551137\n",
      "[566]\ttrain-mlogloss:0.403975\ttest-mlogloss:0.551099\n",
      "[567]\ttrain-mlogloss:0.403895\ttest-mlogloss:0.551077\n",
      "[568]\ttrain-mlogloss:0.403727\ttest-mlogloss:0.551091\n",
      "[569]\ttrain-mlogloss:0.40363\ttest-mlogloss:0.551077\n",
      "[570]\ttrain-mlogloss:0.403505\ttest-mlogloss:0.551059\n",
      "[571]\ttrain-mlogloss:0.403449\ttest-mlogloss:0.551073\n",
      "[572]\ttrain-mlogloss:0.403406\ttest-mlogloss:0.551072\n",
      "[573]\ttrain-mlogloss:0.403331\ttest-mlogloss:0.551055\n",
      "[574]\ttrain-mlogloss:0.403123\ttest-mlogloss:0.55104\n",
      "[575]\ttrain-mlogloss:0.402996\ttest-mlogloss:0.551027\n",
      "[576]\ttrain-mlogloss:0.402695\ttest-mlogloss:0.55102\n",
      "[577]\ttrain-mlogloss:0.402561\ttest-mlogloss:0.551001\n",
      "[578]\ttrain-mlogloss:0.402359\ttest-mlogloss:0.551007\n",
      "[579]\ttrain-mlogloss:0.402175\ttest-mlogloss:0.550998\n",
      "[580]\ttrain-mlogloss:0.402028\ttest-mlogloss:0.550998\n",
      "[581]\ttrain-mlogloss:0.401918\ttest-mlogloss:0.550994\n",
      "[582]\ttrain-mlogloss:0.401731\ttest-mlogloss:0.550976\n",
      "[583]\ttrain-mlogloss:0.401494\ttest-mlogloss:0.550977\n",
      "[584]\ttrain-mlogloss:0.401216\ttest-mlogloss:0.550963\n",
      "[585]\ttrain-mlogloss:0.401025\ttest-mlogloss:0.550962\n",
      "[586]\ttrain-mlogloss:0.400815\ttest-mlogloss:0.550926\n",
      "[587]\ttrain-mlogloss:0.400723\ttest-mlogloss:0.550887\n",
      "[588]\ttrain-mlogloss:0.400609\ttest-mlogloss:0.550885\n",
      "[589]\ttrain-mlogloss:0.40049\ttest-mlogloss:0.550875\n",
      "[590]\ttrain-mlogloss:0.400227\ttest-mlogloss:0.550854\n",
      "[591]\ttrain-mlogloss:0.400001\ttest-mlogloss:0.55084\n",
      "[592]\ttrain-mlogloss:0.399709\ttest-mlogloss:0.550885\n",
      "[593]\ttrain-mlogloss:0.399554\ttest-mlogloss:0.550863\n",
      "[594]\ttrain-mlogloss:0.399398\ttest-mlogloss:0.550823\n",
      "[595]\ttrain-mlogloss:0.399343\ttest-mlogloss:0.55084\n",
      "[596]\ttrain-mlogloss:0.399232\ttest-mlogloss:0.550828\n",
      "[597]\ttrain-mlogloss:0.399066\ttest-mlogloss:0.550817\n",
      "[598]\ttrain-mlogloss:0.398847\ttest-mlogloss:0.550803\n",
      "[599]\ttrain-mlogloss:0.398593\ttest-mlogloss:0.550754\n",
      "[600]\ttrain-mlogloss:0.398528\ttest-mlogloss:0.550743\n",
      "[601]\ttrain-mlogloss:0.398382\ttest-mlogloss:0.550762\n",
      "[602]\ttrain-mlogloss:0.398243\ttest-mlogloss:0.550731\n",
      "[603]\ttrain-mlogloss:0.398107\ttest-mlogloss:0.550712\n",
      "[604]\ttrain-mlogloss:0.397943\ttest-mlogloss:0.550718\n",
      "[605]\ttrain-mlogloss:0.397724\ttest-mlogloss:0.550693\n",
      "[606]\ttrain-mlogloss:0.397542\ttest-mlogloss:0.550707\n",
      "[607]\ttrain-mlogloss:0.397428\ttest-mlogloss:0.550652\n",
      "[608]\ttrain-mlogloss:0.397292\ttest-mlogloss:0.550649\n",
      "[609]\ttrain-mlogloss:0.397187\ttest-mlogloss:0.550656\n",
      "[610]\ttrain-mlogloss:0.396996\ttest-mlogloss:0.55065\n",
      "[611]\ttrain-mlogloss:0.396787\ttest-mlogloss:0.550606\n",
      "[612]\ttrain-mlogloss:0.396706\ttest-mlogloss:0.550608\n",
      "[613]\ttrain-mlogloss:0.396566\ttest-mlogloss:0.550589\n",
      "[614]\ttrain-mlogloss:0.39628\ttest-mlogloss:0.550581\n",
      "[615]\ttrain-mlogloss:0.396158\ttest-mlogloss:0.550561\n",
      "[616]\ttrain-mlogloss:0.39608\ttest-mlogloss:0.550566\n",
      "[617]\ttrain-mlogloss:0.395926\ttest-mlogloss:0.550562\n",
      "[618]\ttrain-mlogloss:0.395801\ttest-mlogloss:0.550574\n",
      "[619]\ttrain-mlogloss:0.395612\ttest-mlogloss:0.550594\n",
      "[620]\ttrain-mlogloss:0.395447\ttest-mlogloss:0.550581\n",
      "[621]\ttrain-mlogloss:0.395267\ttest-mlogloss:0.550563\n",
      "[622]\ttrain-mlogloss:0.395172\ttest-mlogloss:0.550576\n",
      "[623]\ttrain-mlogloss:0.395048\ttest-mlogloss:0.550584\n",
      "[624]\ttrain-mlogloss:0.394783\ttest-mlogloss:0.550588\n",
      "[625]\ttrain-mlogloss:0.394694\ttest-mlogloss:0.550566\n",
      "[626]\ttrain-mlogloss:0.394542\ttest-mlogloss:0.550559\n",
      "[627]\ttrain-mlogloss:0.39431\ttest-mlogloss:0.550549\n",
      "[628]\ttrain-mlogloss:0.394235\ttest-mlogloss:0.550548\n",
      "[629]\ttrain-mlogloss:0.394071\ttest-mlogloss:0.550522\n",
      "[630]\ttrain-mlogloss:0.393936\ttest-mlogloss:0.550529\n",
      "[631]\ttrain-mlogloss:0.39381\ttest-mlogloss:0.550501\n",
      "[632]\ttrain-mlogloss:0.393766\ttest-mlogloss:0.550489\n",
      "[633]\ttrain-mlogloss:0.39368\ttest-mlogloss:0.55051\n",
      "[634]\ttrain-mlogloss:0.393541\ttest-mlogloss:0.55049\n",
      "[635]\ttrain-mlogloss:0.393459\ttest-mlogloss:0.550482\n",
      "[636]\ttrain-mlogloss:0.393439\ttest-mlogloss:0.550486\n",
      "[637]\ttrain-mlogloss:0.393263\ttest-mlogloss:0.550528\n",
      "[638]\ttrain-mlogloss:0.393091\ttest-mlogloss:0.550524\n",
      "[639]\ttrain-mlogloss:0.392826\ttest-mlogloss:0.550546\n",
      "[640]\ttrain-mlogloss:0.392614\ttest-mlogloss:0.550535\n",
      "[641]\ttrain-mlogloss:0.392367\ttest-mlogloss:0.550504\n",
      "[642]\ttrain-mlogloss:0.392254\ttest-mlogloss:0.550449\n",
      "[643]\ttrain-mlogloss:0.392084\ttest-mlogloss:0.550436\n",
      "[644]\ttrain-mlogloss:0.391966\ttest-mlogloss:0.550453\n",
      "[645]\ttrain-mlogloss:0.391806\ttest-mlogloss:0.550452\n",
      "[646]\ttrain-mlogloss:0.391642\ttest-mlogloss:0.55046\n",
      "[647]\ttrain-mlogloss:0.391491\ttest-mlogloss:0.550416\n",
      "[648]\ttrain-mlogloss:0.391312\ttest-mlogloss:0.55043\n",
      "[649]\ttrain-mlogloss:0.391146\ttest-mlogloss:0.550416\n",
      "[650]\ttrain-mlogloss:0.391055\ttest-mlogloss:0.550392\n",
      "[651]\ttrain-mlogloss:0.391025\ttest-mlogloss:0.550371\n",
      "[652]\ttrain-mlogloss:0.390845\ttest-mlogloss:0.550369\n",
      "[653]\ttrain-mlogloss:0.39072\ttest-mlogloss:0.550346\n",
      "[654]\ttrain-mlogloss:0.390505\ttest-mlogloss:0.550309\n",
      "[655]\ttrain-mlogloss:0.390248\ttest-mlogloss:0.550303\n",
      "[656]\ttrain-mlogloss:0.390041\ttest-mlogloss:0.550297\n",
      "[657]\ttrain-mlogloss:0.389929\ttest-mlogloss:0.550314\n",
      "[658]\ttrain-mlogloss:0.389757\ttest-mlogloss:0.55031\n",
      "[659]\ttrain-mlogloss:0.389482\ttest-mlogloss:0.550278\n",
      "[660]\ttrain-mlogloss:0.389391\ttest-mlogloss:0.55026\n",
      "[661]\ttrain-mlogloss:0.389284\ttest-mlogloss:0.550267\n",
      "[662]\ttrain-mlogloss:0.389142\ttest-mlogloss:0.550251\n",
      "[663]\ttrain-mlogloss:0.388967\ttest-mlogloss:0.550212\n",
      "[664]\ttrain-mlogloss:0.388942\ttest-mlogloss:0.550211\n",
      "[665]\ttrain-mlogloss:0.388756\ttest-mlogloss:0.550177\n",
      "[666]\ttrain-mlogloss:0.388694\ttest-mlogloss:0.550173\n",
      "[667]\ttrain-mlogloss:0.388481\ttest-mlogloss:0.550139\n",
      "[668]\ttrain-mlogloss:0.388333\ttest-mlogloss:0.550164\n",
      "[669]\ttrain-mlogloss:0.388198\ttest-mlogloss:0.550164\n",
      "[670]\ttrain-mlogloss:0.388129\ttest-mlogloss:0.550172\n",
      "[671]\ttrain-mlogloss:0.38798\ttest-mlogloss:0.550144\n",
      "[672]\ttrain-mlogloss:0.387873\ttest-mlogloss:0.550121\n",
      "[673]\ttrain-mlogloss:0.387747\ttest-mlogloss:0.550143\n",
      "[674]\ttrain-mlogloss:0.387722\ttest-mlogloss:0.550131\n",
      "[675]\ttrain-mlogloss:0.387504\ttest-mlogloss:0.550122\n",
      "[676]\ttrain-mlogloss:0.387328\ttest-mlogloss:0.550112\n",
      "[677]\ttrain-mlogloss:0.387255\ttest-mlogloss:0.550115\n",
      "[678]\ttrain-mlogloss:0.387218\ttest-mlogloss:0.550127\n",
      "[679]\ttrain-mlogloss:0.38699\ttest-mlogloss:0.550138\n",
      "[680]\ttrain-mlogloss:0.386906\ttest-mlogloss:0.550151\n",
      "[681]\ttrain-mlogloss:0.38676\ttest-mlogloss:0.550136\n",
      "[682]\ttrain-mlogloss:0.386657\ttest-mlogloss:0.550147\n",
      "[683]\ttrain-mlogloss:0.38641\ttest-mlogloss:0.550142\n",
      "[684]\ttrain-mlogloss:0.38641\ttest-mlogloss:0.550143\n",
      "[685]\ttrain-mlogloss:0.38628\ttest-mlogloss:0.550144\n",
      "[686]\ttrain-mlogloss:0.386136\ttest-mlogloss:0.550163\n",
      "[687]\ttrain-mlogloss:0.386034\ttest-mlogloss:0.550131\n",
      "[688]\ttrain-mlogloss:0.386034\ttest-mlogloss:0.550131\n",
      "[689]\ttrain-mlogloss:0.385952\ttest-mlogloss:0.550121\n",
      "[690]\ttrain-mlogloss:0.385763\ttest-mlogloss:0.550068\n",
      "[691]\ttrain-mlogloss:0.385634\ttest-mlogloss:0.550059\n",
      "[692]\ttrain-mlogloss:0.385456\ttest-mlogloss:0.550053\n",
      "[693]\ttrain-mlogloss:0.385405\ttest-mlogloss:0.55006\n",
      "[694]\ttrain-mlogloss:0.385405\ttest-mlogloss:0.55006\n",
      "[695]\ttrain-mlogloss:0.385238\ttest-mlogloss:0.550081\n",
      "[696]\ttrain-mlogloss:0.385113\ttest-mlogloss:0.550065\n",
      "[697]\ttrain-mlogloss:0.384987\ttest-mlogloss:0.550054\n",
      "[698]\ttrain-mlogloss:0.384809\ttest-mlogloss:0.550045\n",
      "[699]\ttrain-mlogloss:0.384535\ttest-mlogloss:0.55007\n",
      "[700]\ttrain-mlogloss:0.384465\ttest-mlogloss:0.550045\n",
      "[701]\ttrain-mlogloss:0.384246\ttest-mlogloss:0.550058\n",
      "[702]\ttrain-mlogloss:0.38415\ttest-mlogloss:0.550049\n",
      "[703]\ttrain-mlogloss:0.384019\ttest-mlogloss:0.550028\n",
      "[704]\ttrain-mlogloss:0.383856\ttest-mlogloss:0.550021\n",
      "[705]\ttrain-mlogloss:0.383776\ttest-mlogloss:0.55003\n",
      "[706]\ttrain-mlogloss:0.383723\ttest-mlogloss:0.550029\n",
      "[707]\ttrain-mlogloss:0.383543\ttest-mlogloss:0.550024\n",
      "[708]\ttrain-mlogloss:0.383448\ttest-mlogloss:0.550024\n",
      "[709]\ttrain-mlogloss:0.383304\ttest-mlogloss:0.550037\n",
      "[710]\ttrain-mlogloss:0.383152\ttest-mlogloss:0.550031\n",
      "[711]\ttrain-mlogloss:0.383033\ttest-mlogloss:0.550068\n",
      "[712]\ttrain-mlogloss:0.382817\ttest-mlogloss:0.550063\n",
      "[713]\ttrain-mlogloss:0.382728\ttest-mlogloss:0.550042\n",
      "[714]\ttrain-mlogloss:0.382599\ttest-mlogloss:0.550001\n",
      "[715]\ttrain-mlogloss:0.382534\ttest-mlogloss:0.550017\n",
      "[716]\ttrain-mlogloss:0.382373\ttest-mlogloss:0.549988\n",
      "[717]\ttrain-mlogloss:0.382284\ttest-mlogloss:0.549977\n",
      "[718]\ttrain-mlogloss:0.382116\ttest-mlogloss:0.549964\n",
      "[719]\ttrain-mlogloss:0.38186\ttest-mlogloss:0.549922\n",
      "[720]\ttrain-mlogloss:0.381618\ttest-mlogloss:0.549885\n",
      "[721]\ttrain-mlogloss:0.381439\ttest-mlogloss:0.549846\n",
      "[722]\ttrain-mlogloss:0.381385\ttest-mlogloss:0.549859\n",
      "[723]\ttrain-mlogloss:0.381284\ttest-mlogloss:0.549833\n",
      "[724]\ttrain-mlogloss:0.381032\ttest-mlogloss:0.549803\n",
      "[725]\ttrain-mlogloss:0.380976\ttest-mlogloss:0.549792\n",
      "[726]\ttrain-mlogloss:0.380817\ttest-mlogloss:0.549792\n",
      "[727]\ttrain-mlogloss:0.380632\ttest-mlogloss:0.549761\n",
      "[728]\ttrain-mlogloss:0.380499\ttest-mlogloss:0.549721\n",
      "[729]\ttrain-mlogloss:0.38039\ttest-mlogloss:0.5497\n",
      "[730]\ttrain-mlogloss:0.380313\ttest-mlogloss:0.54969\n",
      "[731]\ttrain-mlogloss:0.380212\ttest-mlogloss:0.549685\n",
      "[732]\ttrain-mlogloss:0.380083\ttest-mlogloss:0.549638\n",
      "[733]\ttrain-mlogloss:0.37988\ttest-mlogloss:0.549635\n",
      "[734]\ttrain-mlogloss:0.379719\ttest-mlogloss:0.54964\n",
      "[735]\ttrain-mlogloss:0.379625\ttest-mlogloss:0.549639\n",
      "[736]\ttrain-mlogloss:0.379482\ttest-mlogloss:0.549607\n",
      "[737]\ttrain-mlogloss:0.37938\ttest-mlogloss:0.549624\n",
      "[738]\ttrain-mlogloss:0.379274\ttest-mlogloss:0.549606\n",
      "[739]\ttrain-mlogloss:0.379196\ttest-mlogloss:0.549579\n",
      "[740]\ttrain-mlogloss:0.379108\ttest-mlogloss:0.549566\n",
      "[741]\ttrain-mlogloss:0.378915\ttest-mlogloss:0.549564\n",
      "[742]\ttrain-mlogloss:0.378801\ttest-mlogloss:0.549547\n",
      "[743]\ttrain-mlogloss:0.37867\ttest-mlogloss:0.549551\n",
      "[744]\ttrain-mlogloss:0.378526\ttest-mlogloss:0.549535\n",
      "[745]\ttrain-mlogloss:0.378379\ttest-mlogloss:0.549555\n",
      "[746]\ttrain-mlogloss:0.378156\ttest-mlogloss:0.549547\n",
      "[747]\ttrain-mlogloss:0.378155\ttest-mlogloss:0.549546\n",
      "[748]\ttrain-mlogloss:0.377967\ttest-mlogloss:0.54956\n",
      "[749]\ttrain-mlogloss:0.377893\ttest-mlogloss:0.549561\n",
      "[750]\ttrain-mlogloss:0.377862\ttest-mlogloss:0.549566\n",
      "[751]\ttrain-mlogloss:0.377804\ttest-mlogloss:0.549554\n",
      "[752]\ttrain-mlogloss:0.377757\ttest-mlogloss:0.54955\n",
      "[753]\ttrain-mlogloss:0.377574\ttest-mlogloss:0.549555\n",
      "[754]\ttrain-mlogloss:0.377365\ttest-mlogloss:0.549519\n",
      "[755]\ttrain-mlogloss:0.377203\ttest-mlogloss:0.549524\n",
      "[756]\ttrain-mlogloss:0.377176\ttest-mlogloss:0.549535\n",
      "[757]\ttrain-mlogloss:0.377139\ttest-mlogloss:0.549538\n",
      "[758]\ttrain-mlogloss:0.37708\ttest-mlogloss:0.549542\n",
      "[759]\ttrain-mlogloss:0.376957\ttest-mlogloss:0.549546\n",
      "[760]\ttrain-mlogloss:0.376839\ttest-mlogloss:0.549539\n",
      "[761]\ttrain-mlogloss:0.376736\ttest-mlogloss:0.549504\n",
      "[762]\ttrain-mlogloss:0.376613\ttest-mlogloss:0.549465\n",
      "[763]\ttrain-mlogloss:0.376555\ttest-mlogloss:0.549451\n",
      "[764]\ttrain-mlogloss:0.376365\ttest-mlogloss:0.549431\n",
      "[765]\ttrain-mlogloss:0.37628\ttest-mlogloss:0.54948\n",
      "[766]\ttrain-mlogloss:0.376148\ttest-mlogloss:0.54946\n",
      "[767]\ttrain-mlogloss:0.376085\ttest-mlogloss:0.549432\n",
      "[768]\ttrain-mlogloss:0.375958\ttest-mlogloss:0.549415\n",
      "[769]\ttrain-mlogloss:0.375772\ttest-mlogloss:0.549398\n",
      "[770]\ttrain-mlogloss:0.375666\ttest-mlogloss:0.549402\n",
      "[771]\ttrain-mlogloss:0.375606\ttest-mlogloss:0.54937\n",
      "[772]\ttrain-mlogloss:0.375353\ttest-mlogloss:0.549375\n",
      "[773]\ttrain-mlogloss:0.375254\ttest-mlogloss:0.54936\n",
      "[774]\ttrain-mlogloss:0.375115\ttest-mlogloss:0.549363\n",
      "[775]\ttrain-mlogloss:0.375079\ttest-mlogloss:0.54936\n",
      "[776]\ttrain-mlogloss:0.374991\ttest-mlogloss:0.549356\n",
      "[777]\ttrain-mlogloss:0.374909\ttest-mlogloss:0.549355\n",
      "[778]\ttrain-mlogloss:0.374771\ttest-mlogloss:0.549316\n",
      "[779]\ttrain-mlogloss:0.374685\ttest-mlogloss:0.549318\n",
      "[780]\ttrain-mlogloss:0.374591\ttest-mlogloss:0.549311\n",
      "[781]\ttrain-mlogloss:0.374516\ttest-mlogloss:0.549313\n",
      "[782]\ttrain-mlogloss:0.374412\ttest-mlogloss:0.549295\n",
      "[783]\ttrain-mlogloss:0.374192\ttest-mlogloss:0.549307\n",
      "[784]\ttrain-mlogloss:0.373988\ttest-mlogloss:0.549286\n",
      "[785]\ttrain-mlogloss:0.373988\ttest-mlogloss:0.549285\n",
      "[786]\ttrain-mlogloss:0.37387\ttest-mlogloss:0.549261\n",
      "[787]\ttrain-mlogloss:0.373719\ttest-mlogloss:0.549246\n",
      "[788]\ttrain-mlogloss:0.373558\ttest-mlogloss:0.549224\n",
      "[789]\ttrain-mlogloss:0.373401\ttest-mlogloss:0.549201\n",
      "[790]\ttrain-mlogloss:0.373308\ttest-mlogloss:0.549204\n",
      "[791]\ttrain-mlogloss:0.373223\ttest-mlogloss:0.5492\n",
      "[792]\ttrain-mlogloss:0.373142\ttest-mlogloss:0.54919\n",
      "[793]\ttrain-mlogloss:0.372991\ttest-mlogloss:0.549183\n",
      "[794]\ttrain-mlogloss:0.372824\ttest-mlogloss:0.549192\n",
      "[795]\ttrain-mlogloss:0.372674\ttest-mlogloss:0.549205\n",
      "[796]\ttrain-mlogloss:0.372631\ttest-mlogloss:0.549187\n",
      "[797]\ttrain-mlogloss:0.372483\ttest-mlogloss:0.549196\n",
      "[798]\ttrain-mlogloss:0.372315\ttest-mlogloss:0.549211\n",
      "[799]\ttrain-mlogloss:0.372262\ttest-mlogloss:0.549215\n",
      "[800]\ttrain-mlogloss:0.372134\ttest-mlogloss:0.549229\n",
      "[801]\ttrain-mlogloss:0.37209\ttest-mlogloss:0.549217\n",
      "[802]\ttrain-mlogloss:0.371988\ttest-mlogloss:0.549224\n",
      "[803]\ttrain-mlogloss:0.371892\ttest-mlogloss:0.549223\n",
      "[804]\ttrain-mlogloss:0.371853\ttest-mlogloss:0.549227\n",
      "[805]\ttrain-mlogloss:0.371729\ttest-mlogloss:0.549217\n",
      "[806]\ttrain-mlogloss:0.371717\ttest-mlogloss:0.549216\n",
      "[807]\ttrain-mlogloss:0.37166\ttest-mlogloss:0.549217\n",
      "[808]\ttrain-mlogloss:0.371657\ttest-mlogloss:0.549213\n",
      "[809]\ttrain-mlogloss:0.371651\ttest-mlogloss:0.549215\n",
      "[810]\ttrain-mlogloss:0.3715\ttest-mlogloss:0.549201\n",
      "[811]\ttrain-mlogloss:0.371452\ttest-mlogloss:0.54919\n",
      "[812]\ttrain-mlogloss:0.371252\ttest-mlogloss:0.54918\n",
      "[813]\ttrain-mlogloss:0.371238\ttest-mlogloss:0.549171\n",
      "[814]\ttrain-mlogloss:0.371203\ttest-mlogloss:0.54917\n",
      "[815]\ttrain-mlogloss:0.371167\ttest-mlogloss:0.549181\n",
      "[816]\ttrain-mlogloss:0.371076\ttest-mlogloss:0.549193\n",
      "[817]\ttrain-mlogloss:0.371076\ttest-mlogloss:0.549194\n",
      "[818]\ttrain-mlogloss:0.370909\ttest-mlogloss:0.549196\n",
      "[819]\ttrain-mlogloss:0.370788\ttest-mlogloss:0.549207\n",
      "[820]\ttrain-mlogloss:0.370617\ttest-mlogloss:0.549205\n",
      "[821]\ttrain-mlogloss:0.370508\ttest-mlogloss:0.549213\n",
      "[822]\ttrain-mlogloss:0.370407\ttest-mlogloss:0.549242\n",
      "[823]\ttrain-mlogloss:0.370321\ttest-mlogloss:0.549232\n",
      "[824]\ttrain-mlogloss:0.370286\ttest-mlogloss:0.54923\n",
      "[825]\ttrain-mlogloss:0.370038\ttest-mlogloss:0.549206\n",
      "[826]\ttrain-mlogloss:0.369873\ttest-mlogloss:0.549161\n",
      "[827]\ttrain-mlogloss:0.3698\ttest-mlogloss:0.549137\n",
      "[828]\ttrain-mlogloss:0.369667\ttest-mlogloss:0.549137\n",
      "[829]\ttrain-mlogloss:0.369561\ttest-mlogloss:0.549147\n",
      "[830]\ttrain-mlogloss:0.369448\ttest-mlogloss:0.549126\n",
      "[831]\ttrain-mlogloss:0.369398\ttest-mlogloss:0.549153\n",
      "[832]\ttrain-mlogloss:0.369345\ttest-mlogloss:0.549161\n",
      "[833]\ttrain-mlogloss:0.369227\ttest-mlogloss:0.54916\n",
      "[834]\ttrain-mlogloss:0.369173\ttest-mlogloss:0.549164\n",
      "[835]\ttrain-mlogloss:0.369065\ttest-mlogloss:0.549147\n",
      "[836]\ttrain-mlogloss:0.368972\ttest-mlogloss:0.549157\n",
      "[837]\ttrain-mlogloss:0.368921\ttest-mlogloss:0.549157\n",
      "[838]\ttrain-mlogloss:0.368921\ttest-mlogloss:0.549158\n",
      "[839]\ttrain-mlogloss:0.368807\ttest-mlogloss:0.549183\n",
      "[840]\ttrain-mlogloss:0.368729\ttest-mlogloss:0.549177\n",
      "[841]\ttrain-mlogloss:0.368485\ttest-mlogloss:0.549198\n",
      "[842]\ttrain-mlogloss:0.368436\ttest-mlogloss:0.549192\n",
      "[843]\ttrain-mlogloss:0.368352\ttest-mlogloss:0.549205\n",
      "[844]\ttrain-mlogloss:0.368312\ttest-mlogloss:0.549214\n",
      "[845]\ttrain-mlogloss:0.368312\ttest-mlogloss:0.549215\n",
      "[846]\ttrain-mlogloss:0.368198\ttest-mlogloss:0.549218\n",
      "[847]\ttrain-mlogloss:0.367998\ttest-mlogloss:0.549186\n",
      "[848]\ttrain-mlogloss:0.367924\ttest-mlogloss:0.549173\n",
      "[849]\ttrain-mlogloss:0.367669\ttest-mlogloss:0.549134\n",
      "[850]\ttrain-mlogloss:0.367596\ttest-mlogloss:0.549123\n",
      "[851]\ttrain-mlogloss:0.367506\ttest-mlogloss:0.549133\n",
      "[852]\ttrain-mlogloss:0.367397\ttest-mlogloss:0.549113\n",
      "[853]\ttrain-mlogloss:0.367292\ttest-mlogloss:0.549131\n",
      "[854]\ttrain-mlogloss:0.367094\ttest-mlogloss:0.54909\n",
      "[855]\ttrain-mlogloss:0.366969\ttest-mlogloss:0.54909\n",
      "[856]\ttrain-mlogloss:0.366841\ttest-mlogloss:0.549069\n",
      "[857]\ttrain-mlogloss:0.366782\ttest-mlogloss:0.549059\n",
      "[858]\ttrain-mlogloss:0.366657\ttest-mlogloss:0.549063\n",
      "[859]\ttrain-mlogloss:0.366606\ttest-mlogloss:0.549055\n",
      "[860]\ttrain-mlogloss:0.366556\ttest-mlogloss:0.549071\n",
      "[861]\ttrain-mlogloss:0.366473\ttest-mlogloss:0.549038\n",
      "[862]\ttrain-mlogloss:0.366421\ttest-mlogloss:0.549037\n",
      "[863]\ttrain-mlogloss:0.366356\ttest-mlogloss:0.549021\n",
      "[864]\ttrain-mlogloss:0.366251\ttest-mlogloss:0.549027\n",
      "[865]\ttrain-mlogloss:0.366251\ttest-mlogloss:0.549028\n",
      "[866]\ttrain-mlogloss:0.366238\ttest-mlogloss:0.549019\n",
      "[867]\ttrain-mlogloss:0.366238\ttest-mlogloss:0.54902\n",
      "[868]\ttrain-mlogloss:0.36619\ttest-mlogloss:0.549019\n",
      "[869]\ttrain-mlogloss:0.36609\ttest-mlogloss:0.549047\n",
      "[870]\ttrain-mlogloss:0.365964\ttest-mlogloss:0.549041\n",
      "[871]\ttrain-mlogloss:0.365887\ttest-mlogloss:0.54904\n",
      "[872]\ttrain-mlogloss:0.365753\ttest-mlogloss:0.549062\n",
      "[873]\ttrain-mlogloss:0.365695\ttest-mlogloss:0.54906\n",
      "[874]\ttrain-mlogloss:0.365525\ttest-mlogloss:0.549051\n",
      "[875]\ttrain-mlogloss:0.365425\ttest-mlogloss:0.549057\n",
      "[876]\ttrain-mlogloss:0.36531\ttest-mlogloss:0.549023\n",
      "[877]\ttrain-mlogloss:0.36531\ttest-mlogloss:0.549023\n",
      "[878]\ttrain-mlogloss:0.365262\ttest-mlogloss:0.549016\n",
      "[879]\ttrain-mlogloss:0.365205\ttest-mlogloss:0.549039\n",
      "[880]\ttrain-mlogloss:0.365111\ttest-mlogloss:0.549063\n",
      "[881]\ttrain-mlogloss:0.365053\ttest-mlogloss:0.549043\n",
      "[882]\ttrain-mlogloss:0.365005\ttest-mlogloss:0.549036\n",
      "[883]\ttrain-mlogloss:0.364868\ttest-mlogloss:0.549005\n",
      "[884]\ttrain-mlogloss:0.364713\ttest-mlogloss:0.548957\n",
      "[885]\ttrain-mlogloss:0.364515\ttest-mlogloss:0.548921\n",
      "[886]\ttrain-mlogloss:0.364487\ttest-mlogloss:0.548926\n",
      "[887]\ttrain-mlogloss:0.364402\ttest-mlogloss:0.548921\n",
      "[888]\ttrain-mlogloss:0.364369\ttest-mlogloss:0.5489\n",
      "[889]\ttrain-mlogloss:0.364265\ttest-mlogloss:0.548929\n",
      "[890]\ttrain-mlogloss:0.364159\ttest-mlogloss:0.548938\n",
      "[891]\ttrain-mlogloss:0.364102\ttest-mlogloss:0.548926\n",
      "[892]\ttrain-mlogloss:0.364057\ttest-mlogloss:0.548915\n",
      "[893]\ttrain-mlogloss:0.36402\ttest-mlogloss:0.548916\n",
      "[894]\ttrain-mlogloss:0.363885\ttest-mlogloss:0.548916\n",
      "[895]\ttrain-mlogloss:0.363868\ttest-mlogloss:0.54891\n",
      "[896]\ttrain-mlogloss:0.363803\ttest-mlogloss:0.548898\n",
      "[897]\ttrain-mlogloss:0.363659\ttest-mlogloss:0.548915\n",
      "[898]\ttrain-mlogloss:0.363659\ttest-mlogloss:0.548916\n",
      "[899]\ttrain-mlogloss:0.363559\ttest-mlogloss:0.548873\n",
      "[900]\ttrain-mlogloss:0.36356\ttest-mlogloss:0.548875\n",
      "[901]\ttrain-mlogloss:0.36356\ttest-mlogloss:0.548874\n",
      "[902]\ttrain-mlogloss:0.363511\ttest-mlogloss:0.548863\n",
      "[903]\ttrain-mlogloss:0.363366\ttest-mlogloss:0.548885\n",
      "[904]\ttrain-mlogloss:0.36334\ttest-mlogloss:0.548875\n",
      "[905]\ttrain-mlogloss:0.363193\ttest-mlogloss:0.548847\n",
      "[906]\ttrain-mlogloss:0.36312\ttest-mlogloss:0.548832\n",
      "[907]\ttrain-mlogloss:0.36312\ttest-mlogloss:0.548833\n",
      "[908]\ttrain-mlogloss:0.363064\ttest-mlogloss:0.548847\n",
      "[909]\ttrain-mlogloss:0.362898\ttest-mlogloss:0.548883\n",
      "[910]\ttrain-mlogloss:0.362814\ttest-mlogloss:0.548898\n",
      "[911]\ttrain-mlogloss:0.362683\ttest-mlogloss:0.548908\n",
      "[912]\ttrain-mlogloss:0.362472\ttest-mlogloss:0.548885\n",
      "[913]\ttrain-mlogloss:0.362387\ttest-mlogloss:0.548895\n",
      "[914]\ttrain-mlogloss:0.362355\ttest-mlogloss:0.548897\n",
      "[915]\ttrain-mlogloss:0.362267\ttest-mlogloss:0.548877\n",
      "[916]\ttrain-mlogloss:0.362129\ttest-mlogloss:0.548885\n",
      "[917]\ttrain-mlogloss:0.36191\ttest-mlogloss:0.548918\n",
      "[918]\ttrain-mlogloss:0.361742\ttest-mlogloss:0.548943\n",
      "[919]\ttrain-mlogloss:0.361595\ttest-mlogloss:0.548953\n",
      "[920]\ttrain-mlogloss:0.361408\ttest-mlogloss:0.548971\n",
      "[921]\ttrain-mlogloss:0.361326\ttest-mlogloss:0.548979\n",
      "[922]\ttrain-mlogloss:0.36123\ttest-mlogloss:0.548966\n",
      "[923]\ttrain-mlogloss:0.361133\ttest-mlogloss:0.548965\n",
      "[924]\ttrain-mlogloss:0.361103\ttest-mlogloss:0.54896\n",
      "[925]\ttrain-mlogloss:0.360855\ttest-mlogloss:0.548934\n",
      "[926]\ttrain-mlogloss:0.360802\ttest-mlogloss:0.548942\n",
      "Stopping. Best iteration:\n",
      "[906]\ttrain-mlogloss:0.36312\ttest-mlogloss:0.548832\n",
      "\n",
      "[0.54894200051355269]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
    "        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.54894200051355269]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=1000)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_starter_word2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"previos.png\" width=\"500\" height=\"200\"/>\n",
    "<img src=\"word2vec.png\" width=\"500\" height=\"200\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
